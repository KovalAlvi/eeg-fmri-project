{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57334e36-39bf-4342-ab23-5bf0868237b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab4de19-cc35-47c2-912c-d1dc3372c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json\n",
    "import mne, sklearn, wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from nilearn import datasets, image, masking, plotting\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "\n",
    "\n",
    "# animation part\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from celluloid import Camera   # it is convinient method to animate\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "## torch libraries \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from pytorch_model_summary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68eacc99-823f-49be-80b1-b432a1833d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from utils import get_datasets\n",
    "from utils import preproc\n",
    "from utils import torch_dataset\n",
    "from utils import train_utils\n",
    "from utils import inference\n",
    "from utils.models_arch import autoencoder_v3\n",
    "from utils.models_arch import vq_autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974b520-53af-4aae-8475-ad9864cc86f0",
   "metadata": {},
   "source": [
    "# Set all hyperparameters\n",
    "- Cuda and GPU.\n",
    "- Parameters of dataset. \n",
    "- random seed( if necessary). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9740a7b-6c36-471f-bafe-3361c4758086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68da9ec-be91-4cc8-b7d2-87c106d53ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(  \n",
    "                dataset_name = 'CWL', # NODDI\n",
    "                fps = 250,\n",
    "                new_fps=250, \n",
    "                n_channels = 30, # 64 \n",
    "                # n_roi = 30,\n",
    "                test_sec = 60, # in seconds.\n",
    "                freqs = np.linspace(2, 100, 16), \n",
    "                \n",
    "                \n",
    "                bold_delay = 0,\n",
    "                to_many = True,\n",
    "                random_subsample = True,\n",
    "                sample_per_epoch = 25600, \n",
    "                WINDOW_SIZE = 2048,\n",
    "                    \n",
    "                optimizer='adam',\n",
    "                lr=0.0001,\n",
    "                weight_decay=0, \n",
    "                batch_size=32, \n",
    "\n",
    "                loss_function = 'mae', \n",
    "                model_type = 'VQ_1D_CNN_AE_EEG'\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "hp_autoencoder = dict(n_electrodes=config['n_channels'],\n",
    "                      n_freqs = len(config['freqs']),\n",
    "                      n_channels_out = config['n_channels']*len(config['freqs']),\n",
    "                      channels = [128, 64, 64, 64], \n",
    "                      kernel_sizes=[7, 5, 3],\n",
    "                      strides=[4, 4, 4],\n",
    "                      codebook_size=256)\n",
    "\n",
    "config = {**hp_autoencoder, **config}\n",
    "\n",
    "params_train = {'batch_size': config['batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0}\n",
    "\n",
    "params_val = {'batch_size': config['batch_size'],\n",
    "              'shuffle': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a1c42-68f1-4afa-9943-02a441b15e07",
   "metadata": {},
   "source": [
    "# Upload preprocessed dataset from np files. \n",
    "It should accelerate speed of experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951efaec-ba20-48c9-94aa-588f3f5b13e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (30, 16, 54225) (480, 54225)\n",
      "Size of test dataset: (30, 16, 15000) (480, 15000)\n"
     ]
    }
   ],
   "source": [
    "with open(\"labels_roi.json\", 'r') as f:\n",
    "    labels_roi = json.load(f)\n",
    "\n",
    "\n",
    "if config['dataset_name']=='CWL':\n",
    "    dataset_path = '../data/dataset_cwl_250_hz.npz'\n",
    "    \n",
    "elif config['dataset_name']=='NODDI':\n",
    "    dataset_path = '../data/dataset_NODDI_250_hz.npz'\n",
    "else:\n",
    "    print('no such dataset')\n",
    "\n",
    "\n",
    "# download data\n",
    "data = np.load(dataset_path)\n",
    "eeg_train_cliped = np.log(np.clip(data['x_train'], 0, np.max(data['x_train'])) + 0.0000001)\n",
    "eeg_test_cliped = np.log(np.clip(data['x_test'], 0, np.max(data['x_test'])) + 0.0000001)\n",
    "\n",
    "\n",
    "train_dataset_prep = (eeg_train_cliped, eeg_train_cliped.reshape([-1, eeg_train_cliped.shape[-1]]))\n",
    "test_dataset_prep = (eeg_test_cliped, eeg_test_cliped.reshape([-1, eeg_test_cliped.shape[-1]]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apply time dealy corrected\n",
    "train_dataset_prep = preproc.bold_time_delay_align(train_dataset_prep, \n",
    "                                                   config['new_fps'],\n",
    "                                                   config['bold_delay'])\n",
    "test_dataset_prep = preproc.bold_time_delay_align(test_dataset_prep, \n",
    "                                                  config['new_fps'],\n",
    "                                                  config['bold_delay'])\n",
    "\n",
    "\n",
    "print('Size of train dataset:', train_dataset_prep[0].shape, train_dataset_prep[1].shape)\n",
    "print('Size of test dataset:', test_dataset_prep[0].shape, test_dataset_prep[1].shape)\n",
    "\n",
    "# torch dataset creation \n",
    "torch_dataset_train = torch_dataset.CreateDataset_eeg_fmri(train_dataset_prep, \n",
    "                                                            random_sample=config['random_subsample'], \n",
    "                                                            sample_per_epoch=config['sample_per_epoch'], \n",
    "                                                            to_many=config['to_many'], \n",
    "                                                            window_size = config['WINDOW_SIZE'])\n",
    "\n",
    "torch_dataset_test = torch_dataset.CreateDataset_eeg_fmri(test_dataset_prep, \n",
    "                                                            random_sample=False, \n",
    "                                                            sample_per_epoch=None, \n",
    "                                                            to_many=config['to_many'], \n",
    "                                                            window_size = config['WINDOW_SIZE'])\n",
    "\n",
    "\n",
    "# init dataloaders for training\n",
    "train_loader = torch.utils.data.DataLoader(torch_dataset_train, **params_train)\n",
    "val_loader = torch.utils.data.DataLoader(torch_dataset_test, **params_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff0863-786a-4c24-9130-c997833869c1",
   "metadata": {},
   "source": [
    "# Init Model, Loss, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbf8773-4974-4ee4-bf7a-758c704f4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------\n",
      "          Layer (type)                        Output Shape         Param #     Tr. Param #\n",
      "===========================================================================================\n",
      "              Conv1d-1                      [4, 128, 2048]          61,568          61,568\n",
      "             Block1D-2                        [4, 64, 512]          25,664          25,664\n",
      "             Block1D-3                        [4, 64, 128]          21,568          21,568\n",
      "             Block1D-4                         [4, 64, 32]          21,568          21,568\n",
      "   VectorQuantizer1D-5     [], [4, 64, 32], [], [128, 256]          16,384          16,384\n",
      "   UpsampleConvBlock-6                        [4, 64, 128]          21,568          21,568\n",
      "   UpsampleConvBlock-7                        [4, 64, 512]          21,568          21,568\n",
      "   UpsampleConvBlock-8                      [4, 128, 2048]          75,904          75,904\n",
      "              Conv1d-9                      [4, 480, 2048]          61,920          61,920\n",
      "===========================================================================================\n",
      "Total params: 327,712\n",
      "Trainable params: 327,712\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv_torch/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = vq_autoencoder.VQ_AutoEncoder1D(**hp_autoencoder)\n",
    "\n",
    "loss_func = train_utils.make_mae_loss()\n",
    "train_step = train_utils.train_step\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=config['lr'], \n",
    "                       weight_decay=config['weight_decay'])\n",
    "\n",
    "\n",
    "print(summary(model, torch.zeros(4, config['n_channels'], \n",
    "                                 len(config['freqs']),\n",
    "                                 config['WINDOW_SIZE']), show_input=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e4982-344f-4d44-8d7e-445f4c4a5662",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc68c77-49f9-4ce7-9d72-571a28a571bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inference functions \n",
    "\n",
    "def eeg_inference(y_pred, y_true, n_freq=16):\n",
    "    \"\"\"\n",
    "    Input shape is [n_channels*n_freq, time]\n",
    "    n_freq - 16 by default\n",
    "    \"\"\"\n",
    "    n_ch_freq, time = y_pred.shape\n",
    "    n_ch = n_ch_freq//n_freq\n",
    "    y_pred = y_pred.reshape(-1, n_freq, time)\n",
    "    y_true = y_true.reshape(-1, n_freq, time)\n",
    "    \n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(n_freq, 2, figsize = (8,17),sharex=True, sharey=True, \n",
    "                          )\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0)\n",
    "\n",
    "    for f in range(n_freq):\n",
    "        ax[f, 0].imshow(y_pred[:,f, ::4], aspect = 'auto')\n",
    "        ax[f, 1].imshow(y_true[:,f, ::4], aspect = 'auto')\n",
    "        \n",
    "\n",
    "    return fig\n",
    "\n",
    "def eeg_inference_function(model, dataset, labels, device='cuda',to_many=True):\n",
    "    y_hats, y_true = inference.make_inference_seq_2_seq(model, dataset, device=device)\n",
    "    fig = eeg_inference(y_true, y_hats)\n",
    "    corrs = inference.calculate_corrs(y_prediction=y_hats, y_test=y_true)\n",
    "    \n",
    "    \n",
    "    fig_bars = plt.figure(figsize = (8, 8), dpi= 125)\n",
    "    plt.bar(np.arange(len(corrs)), corrs)\n",
    "    plt.ylim(-1, 1)\n",
    "    \n",
    "    return fig, fig_bars, corrs\n",
    "                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d466a2d-d5c1-4f8f-9128-907286e103ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_batch, y_batch, model, optimizer, loss_function):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_hat, codebook_loss, perp = model(x_batch)\n",
    "    rec_losses = loss_function(y_hat, y_batch)\n",
    "    \n",
    "    sum_loss = 0.25*codebook_loss + rec_losses[0]\n",
    "    sum_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    losses = [sum_loss , codebook_loss, perp]\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2034dd1-feac-4e1e-902e-34378b0a6d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 15000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_prep[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d21727-423a-4872-8bec-82fbd3b4fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkoval_alvi\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/koval_alvi/eeg_fmri/runs/3nrp082w\" target=\"_blank\">classic-sound-136</a></strong> to <a href=\"https://wandb.ai/koval_alvi/eeg_fmri\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_electrodes': 30, 'n_freqs': 16, 'n_channels_out': 480, 'channels': [128, 64, 64, 64], 'kernel_sizes': [7, 5, 3], 'strides': [4, 4, 4], 'codebook_size': 256, 'dataset_name': 'CWL', 'fps': 250, 'new_fps': 250, 'n_channels': 30, 'test_sec': 60, 'freqs': array([  2.        ,   8.53333333,  15.06666667,  21.6       ,\n",
      "        28.13333333,  34.66666667,  41.2       ,  47.73333333,\n",
      "        54.26666667,  60.8       ,  67.33333333,  73.86666667,\n",
      "        80.4       ,  86.93333333,  93.46666667, 100.        ]), 'bold_delay': 0, 'to_many': True, 'random_subsample': True, 'sample_per_epoch': 25600, 'WINDOW_SIZE': 2048, 'optimizer': 'adam', 'lr': 0.0001, 'weight_decay': 0, 'batch_size': 32, 'loss_function': 'mae', 'model_type': 'VQ_1D_CNN_AE_EEG'}\n",
      "VQ_AutoEncoder1D(\n",
      "  (spatial_reduce): Conv1d(480, 128, kernel_size=(1,), stride=(1,))\n",
      "  (downsample_blocks): ModuleList(\n",
      "    (0): Block1D(\n",
      "      (downsample): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
      "      (conv1d): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "      (activation): GELU()\n",
      "      (conv_branch): Sequential(\n",
      "        (0): SepConv1D(\n",
      "          (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "          (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): GELU()\n",
      "        (2): SepConv1D(\n",
      "          (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "          (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (norm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (1): Block1D(\n",
      "      (downsample): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
      "      (conv1d): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (activation): GELU()\n",
      "      (conv_branch): Sequential(\n",
      "        (0): SepConv1D(\n",
      "          (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "          (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): GELU()\n",
      "        (2): SepConv1D(\n",
      "          (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "          (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (norm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "    (2): Block1D(\n",
      "      (downsample): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
      "      (conv1d): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "      (activation): GELU()\n",
      "      (conv_branch): Sequential(\n",
      "        (0): SepConv1D(\n",
      "          (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "          (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "        (1): GELU()\n",
      "        (2): SepConv1D(\n",
      "          (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "          (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "      (norm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (vq_layer): VectorQuantizer1D(\n",
      "    (_embedding): Embedding(256, 64)\n",
      "  )\n",
      "  (upsample_blocks): ModuleList(\n",
      "    (0): UpsampleConvBlock(\n",
      "      (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "      (conv_block): Block1D(\n",
      "        (downsample): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "        (conv1d): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "        (activation): GELU()\n",
      "        (conv_branch): Sequential(\n",
      "          (0): SepConv1D(\n",
      "            (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): SepConv1D(\n",
      "            (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (norm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (1): UpsampleConvBlock(\n",
      "      (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "      (conv_block): Block1D(\n",
      "        (downsample): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "        (conv1d): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "        (activation): GELU()\n",
      "        (conv_branch): Sequential(\n",
      "          (0): SepConv1D(\n",
      "            (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): SepConv1D(\n",
      "            (depthwise): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=same, groups=64, bias=False)\n",
      "            (pointwise): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (norm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (2): UpsampleConvBlock(\n",
      "      (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "      (conv_block): Block1D(\n",
      "        (downsample): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "        (conv1d): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (activation): GELU()\n",
      "        (conv_branch): Sequential(\n",
      "          (0): SepConv1D(\n",
      "            (depthwise): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=same, groups=128, bias=False)\n",
      "            (pointwise): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): SepConv1D(\n",
      "            (depthwise): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=same, groups=128, bias=False)\n",
      "            (pointwise): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (norm): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1x1_one): Conv1d(128, 480, kernel_size=(1,), stride=(1,), padding=same)\n",
      ")\n",
      "-------------------------------------------------------------------------------------------\n",
      "          Layer (type)                        Output Shape         Param #     Tr. Param #\n",
      "===========================================================================================\n",
      "              Conv1d-1                      [4, 128, 2048]          61,568          61,568\n",
      "             Block1D-2                        [4, 64, 512]          25,664          25,664\n",
      "             Block1D-3                        [4, 64, 128]          21,568          21,568\n",
      "             Block1D-4                         [4, 64, 32]          21,568          21,568\n",
      "   VectorQuantizer1D-5     [], [4, 64, 32], [], [128, 256]          16,384          16,384\n",
      "   UpsampleConvBlock-6                        [4, 64, 128]          21,568          21,568\n",
      "   UpsampleConvBlock-7                        [4, 64, 512]          21,568          21,568\n",
      "   UpsampleConvBlock-8                      [4, 128, 2048]          75,904          75,904\n",
      "              Conv1d-9                      [4, 480, 2048]          61,920          61,920\n",
      "===========================================================================================\n",
      "Total params: 327,712\n",
      "Trainable params: 327,712\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------------------\n",
      "Starting Training of our model \n",
      "Number of samples 25600 \n",
      "Size of batch: 32 Number batches 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv_torch/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 1 train loss_0 : 7.13 val loss_0 : 4.03 train loss_1 : 1.24 val loss_1 : 0.763 train loss_2 : 14.5 val loss_2 : 0.0 train loss_3 : 0.0 val loss_3 : 0.0 train loss_4 : 0.0 val loss_4 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 2 train loss_0 : 2.65 val loss_0 : 1.86 train loss_1 : 1.26 val loss_1 : 0.768 train loss_2 : 9.64 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 3 train loss_0 : 2.11 val loss_0 : 1.8 train loss_1 : 1.32 val loss_1 : 0.768 train loss_2 : 9.68 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 4 train loss_0 : 2.12 val loss_0 : 1.79 train loss_1 : 1.43 val loss_1 : 0.768 train loss_2 : 10.7 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 5 train loss_0 : 2.15 val loss_0 : 1.79 train loss_1 : 1.55 val loss_1 : 0.767 train loss_2 : 11.5 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 6 train loss_0 : 2.18 val loss_0 : 1.79 train loss_1 : 1.7 val loss_1 : 0.767 train loss_2 : 13.5 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 7 train loss_0 : 2.21 val loss_0 : 1.79 train loss_1 : 1.83 val loss_1 : 0.767 train loss_2 : 15.8 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 8 train loss_0 : 2.24 val loss_0 : 1.79 train loss_1 : 1.98 val loss_1 : 0.768 train loss_2 : 16.5 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 9 train loss_0 : 2.28 val loss_0 : 1.79 train loss_1 : 2.17 val loss_1 : 0.768 train loss_2 : 17.5 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 10 train loss_0 : 2.33 val loss_0 : 1.79 train loss_1 : 2.37 val loss_1 : 0.768 train loss_2 : 18.5 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 11 train loss_0 : 2.38 val loss_0 : 1.8 train loss_1 : 2.59 val loss_1 : 0.768 train loss_2 : 19.5 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 12 train loss_0 : 2.43 val loss_0 : 1.8 train loss_1 : 2.81 val loss_1 : 0.767 train loss_2 : 21.5 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 13 train loss_0 : 2.49 val loss_0 : 1.8 train loss_1 : 3.04 val loss_1 : 0.767 train loss_2 : 22.2 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 14 train loss_0 : 2.55 val loss_0 : 1.8 train loss_1 : 3.29 val loss_1 : 0.767 train loss_2 : 22.4 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 15 train loss_0 : 2.62 val loss_0 : 1.8 train loss_1 : 3.57 val loss_1 : 0.767 train loss_2 : 23.1 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 16 train loss_0 : 2.69 val loss_0 : 1.81 train loss_1 : 3.86 val loss_1 : 0.766 train loss_2 : 24.1 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 17 train loss_0 : 2.76 val loss_0 : 1.81 train loss_1 : 4.15 val loss_1 : 0.765 train loss_2 : 24.7 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 18 train loss_0 : 2.82 val loss_0 : 1.81 train loss_1 : 4.44 val loss_1 : 0.765 train loss_2 : 25.2 val loss_2 : 0.0 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "n_runs = 3\n",
    "\n",
    "for i in range(n_runs):\n",
    "    \n",
    "    model = vq_autoencoder.VQ_AutoEncoder1D(**hp_autoencoder)\n",
    "\n",
    "    loss_func = train_utils.make_mse_loss()\n",
    "    train_step = train_step\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), \n",
    "                           lr=config['lr'], \n",
    "                           weight_decay=config['weight_decay'])\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        'EPOCHS': 700,\n",
    "        'model': model, \n",
    "        'train_loader': train_loader, \n",
    "        'val_loader': val_loader, \n",
    "        'loss_function': loss_func,\n",
    "        'train_step': train_step,\n",
    "        'optimizer': optimizer, \n",
    "        'device': 'cuda', \n",
    "        'raw_test_data': test_dataset_prep,\n",
    "        'show_info': 1, \n",
    "        'num_losses': 5,\n",
    "        'labels': labels_roi,\n",
    "        'inference_function': eeg_inference_function, \n",
    "        'to_many': config['to_many']\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    path_to_save_wandb = 'common/koval_alvi/Checkpoints/wandb_brain'\n",
    "    \n",
    "    \n",
    "    with wandb.init(project=\"eeg_fmri\", config=config, save_code=True):\n",
    "        \n",
    "        wandb.define_metric(\"val/corr_mean\", summary=\"max\")\n",
    "\n",
    "        if i == 0: \n",
    "            exp_name = wandb.run.name\n",
    "        \n",
    "        wandb.run.name = exp_name +'_run_' + str(i)\n",
    "        \n",
    "        print(config)\n",
    "        print(parameters['model'])\n",
    "        print(summary(model, torch.zeros(4, config['n_channels'], \n",
    "                                         len(config['freqs']),\n",
    "                                         config['WINDOW_SIZE']), show_input=False))\n",
    "        \n",
    "        model = train_utils.wanb_train_regression(**parameters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923ea3f-b6c9-495e-bea2-36552a50cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e40a09-12c2-43b9-957f-8b37d0a0daa8",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_torch",
   "language": "python",
   "name": "myenv_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
