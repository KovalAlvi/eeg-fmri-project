{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57334e36-39bf-4342-ab23-5bf0868237b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab4de19-cc35-47c2-912c-d1dc3372c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv_torch/lib/python3.9/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json\n",
    "import mne, sklearn, wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from nilearn import datasets, image, masking, plotting\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "\n",
    "\n",
    "# animation part\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from celluloid import Camera   # it is convinient method to animate\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "## torch libraries \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from pytorch_model_summary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68eacc99-823f-49be-80b1-b432a1833d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from utils import get_datasets\n",
    "from utils import preproc\n",
    "from utils import torch_dataset\n",
    "from utils import train_utils\n",
    "from utils import inference\n",
    "from utils.models_arch import autoencoder_new, autoencoder_new_Artur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974b520-53af-4aae-8475-ad9864cc86f0",
   "metadata": {},
   "source": [
    "# Set all hyperparameters\n",
    "- Cuda and GPU.\n",
    "- Parameters of dataset. \n",
    "- random seed( if necessary). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9740a7b-6c36-471f-bafe-3361c4758086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 4\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# random.seed(0)  # python operation seed\n",
    "# np.random.seed(0)\n",
    "\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68da9ec-be91-4cc8-b7d2-87c106d53ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(  \n",
    "                dataset_name = 'CWL_raw', # CWL\n",
    "                patients = 'trio1',\n",
    "                fps = 1000,\n",
    "                new_fps=100, \n",
    "                crop_start = 5,\n",
    "                freqs = [-1], \n",
    "    \n",
    "                n_channels = 30, # 63 \n",
    "                n_roi = 8,\n",
    "                \n",
    "                bold_delay = 6,\n",
    "                to_many = True,\n",
    "                random_subsample = True,\n",
    "                sample_per_epoch = 512, \n",
    "                WINDOW_SIZE = 2048,\n",
    "                    \n",
    "                optimizer='adamW',\n",
    "                lr=3e-4,\n",
    "                weight_decay=3e-4, \n",
    "                batch_size=16, \n",
    "                \n",
    "                preproc_type = 'dB_log',\n",
    "                loss_function = 'mse_corr', \n",
    "                model_type = 'Best_AE_Artur_Multi_Head'\n",
    "                )\n",
    "\n",
    "\n",
    "hp_autoencoder = dict(n_electrodes=config['n_channels'],\n",
    "                      n_freqs = len(config['freqs']),\n",
    "                      n_channels_out = config['n_roi'],\n",
    "\n",
    "                     channels = [128, 128, 128, 128], \n",
    "                     kernel_sizes=[5, 5, 3],\n",
    "                     strides=[8, 8, 4], \n",
    "                     dilation=[1, 1, 1], \n",
    "                     decoder_reduce=4, \n",
    "                      hidden_channels = 16,\n",
    "                     )\n",
    "\n",
    "\n",
    "config = {**hp_autoencoder, **config}\n",
    "\n",
    "params_train = {'batch_size': config['batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0}\n",
    "\n",
    "params_val = {'batch_size': config['batch_size'],\n",
    "              'shuffle': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a1c42-68f1-4afa-9943-02a441b15e07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Upload preprocessed dataset from np files. \n",
    "It should accelerate speed of experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9caa3d86-8e41-4b0e-b624-4cf0b264bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/interim/labels_roi_17.json\", 'r') as f:\n",
    "    labels_roi_17 = json.load(f)\n",
    "    \n",
    "labels_roi = ['Left Pallidum',\n",
    "                     'Left Caudate',\n",
    "                     'Left Putamen',\n",
    "                     'Left Accumbens',\n",
    "                      \n",
    "                     'Right Pallidum',\n",
    "                     'Right Caudate',\n",
    "                     'Right Putamen',\n",
    "                     'Right Accumbens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951efaec-ba20-48c9-94aa-588f3f5b13e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (30, 20980) (8, 20980)\n",
      "Size of test dataset: (30, 5400) (8, 5400)\n",
      "3351\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if config['dataset_name']=='CWL_raw':\n",
    "    \n",
    "    dataset_path = f\"../data/interim/CWL/{config['patients']}_1000_filtered_data.npz\"\n",
    "\n",
    "elif config['dataset_name']=='NODDI_raw':\n",
    "    dataset_path = '../data/interim/NODDI/32_250_filtered_data.npz'\n",
    "else:\n",
    "    print('no such dataset')\n",
    "\n",
    "\n",
    "\n",
    "data = np.load(dataset_path)\n",
    "\n",
    "eeg, fmri = data['eeg'], data['fmri']\n",
    "df = pd.DataFrame(data = fmri.T, columns=labels_roi_17)\n",
    "df_filter = df[labels_roi]\n",
    "fmri = df_filter.to_numpy().T\n",
    "\n",
    "# crop start\n",
    "train_crop = config['crop_start']*config['fps']\n",
    "eeg, fmri = eeg[..., train_crop:], fmri[..., train_crop:]\n",
    "\n",
    "# normalize \n",
    "eeg = eeg / np.std(eeg)\n",
    "fmri, fmri_means_stds = preproc.normalize_data(fmri)\n",
    "\n",
    "# train/test split\n",
    "test_time = int(60*config['fps'])\n",
    "train_dataset_prep = (eeg[..., :-test_time], fmri[..., :-test_time])\n",
    "test_dataset_prep = (eeg[..., -test_time:], fmri[..., -test_time:])\n",
    "\n",
    "\n",
    "ds_factor = config['fps']/config['new_fps']\n",
    "train_dataset_prep = preproc.downsample_dataset(train_dataset_prep, factor = ds_factor)\n",
    "test_dataset_prep = preproc.downsample_dataset(test_dataset_prep, factor = ds_factor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apply time dealy corrected\n",
    "train_dataset_prep = preproc.bold_time_delay_align(train_dataset_prep, \n",
    "                                                   config['new_fps'],\n",
    "                                                   config['bold_delay'])\n",
    "test_dataset_prep = preproc.bold_time_delay_align(test_dataset_prep, \n",
    "                                                  config['new_fps'],\n",
    "                                                  config['bold_delay'])\n",
    "\n",
    "\n",
    "print('Size of train dataset:', train_dataset_prep[0].shape, train_dataset_prep[1].shape)\n",
    "print('Size of test dataset:', test_dataset_prep[0].shape, test_dataset_prep[1].shape)\n",
    "\n",
    "# torch dataset creation \n",
    "torch_dataset_train = torch_dataset.CreateDataset_eeg_fmri(train_dataset_prep, \n",
    "                                                            random_sample=config['random_subsample'], \n",
    "                                                            sample_per_epoch=config['sample_per_epoch'], \n",
    "                                                            to_many=config['to_many'], \n",
    "                                                            window_size = config['WINDOW_SIZE'])\n",
    "\n",
    "torch_dataset_test = torch_dataset.CreateDataset_eeg_fmri(test_dataset_prep, \n",
    "                                                            random_sample=False, \n",
    "                                                            sample_per_epoch=None, \n",
    "                                                            to_many=config['to_many'], \n",
    "                                                            window_size = config['WINDOW_SIZE'])\n",
    "print(len(torch_dataset_test))\n",
    "# because you do not have strid for val data. \n",
    "torch_dataset_test = Subset(torch_dataset_test, np.arange(len(torch_dataset_test))[::100])\n",
    "\n",
    "# init dataloaders for training\n",
    "train_loader = torch.utils.data.DataLoader(torch_dataset_train, **params_train)\n",
    "val_loader = torch.utils.data.DataLoader(torch_dataset_test, **params_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff0863-786a-4c24-9130-c997833869c1",
   "metadata": {},
   "source": [
    "# Init Model, Loss, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbf8773-4974-4ee4-bf7a-758c704f4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOW:  {'n_electrodes': 30, 'n_freqs': 1, 'n_channels_out': 8, 'channels': [64, 64, 64, 64], 'kernel_sizes': [5, 5, 3], 'strides': [8, 8, 4], 'dilation': [1, 1, 1], 'decoder_reduce': 2, 'hidden_channels': 16}\n",
      "HUI 8\n",
      "-----------------------------------------------------------------------------\n",
      "            Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=============================================================================\n",
      "   AutoEncoder1D_Artur-1        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-2        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-3        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-4        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-5        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-6        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-7        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-8        [4, 1, 2048]          75,585          75,585\n",
      "=============================================================================\n",
      "Total params: 604,680\n",
      "Trainable params: 604,680\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder_new_Artur.AutoEncoder1D_Artur_MultiHead(hp_autoencoder)\n",
    "\n",
    "print(summary(model, torch.zeros(4, config['n_channels'],\n",
    "                                 config['WINDOW_SIZE']), show_input=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e4982-344f-4d44-8d7e-445f4c4a5662",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d21727-423a-4872-8bec-82fbd3b4fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOW:  {'n_electrodes': 30, 'n_freqs': 1, 'n_channels_out': 8, 'channels': [64, 64, 64, 64], 'kernel_sizes': [5, 5, 3], 'strides': [8, 8, 4], 'dilation': [1, 1, 1], 'decoder_reduce': 2, 'hidden_channels': 16}\n",
      "HUI 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkoval_alvi\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/koval_alvi/eeg_fmri/runs/lyr42ofj\" target=\"_blank\">absurd-shape-458</a></strong> to <a href=\"https://wandb.ai/koval_alvi/eeg_fmri\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_electrodes': 30, 'n_freqs': 1, 'n_channels_out': 8, 'channels': [64, 64, 64, 64], 'kernel_sizes': [5, 5, 3], 'strides': [8, 8, 4], 'dilation': [1, 1, 1], 'decoder_reduce': 2, 'hidden_channels': 16, 'dataset_name': 'CWL_raw', 'patients': 'trio2', 'fps': 1000, 'new_fps': 100, 'crop_start': 5, 'freqs': [-1], 'n_channels': 30, 'n_roi': 8, 'bold_delay': 6, 'to_many': True, 'random_subsample': True, 'sample_per_epoch': 512, 'WINDOW_SIZE': 2048, 'optimizer': 'adamW', 'lr': 0.0003, 'weight_decay': 0.0003, 'batch_size': 16, 'preproc_type': 'dB_log', 'loss_function': 'mse_corr', 'model_type': 'Best_AE_Artur_Multi_Head'}\n",
      "AutoEncoder1D_Artur_MultiHead(\n",
      "  (models): ModuleList(\n",
      "    (0): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "    (1): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "    (2): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "    (3): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "    (4): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "    (5): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "    (6): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "    (7): AutoEncoder1D_Artur(\n",
      "      (artur_block): ArturBlock(\n",
      "        (unmixing_layer): Conv1d(30, 16, kernel_size=(1,), stride=(1,))\n",
      "        (unmixed_channels_batchnorm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (band_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16, bias=False)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "        (act): ReLU()\n",
      "        (low_pass): Conv1d(16, 16, kernel_size=(51,), stride=(1,), padding=same, groups=16)\n",
      "      )\n",
      "      (spatial_reduce): ConvBlock(\n",
      "        (conv1d): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (downsample_blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1d): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation): GELU()\n",
      "          (drop): Dropout(p=0.3, inplace=False)\n",
      "          (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (upsample_blocks): ModuleList(\n",
      "        (0): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "        )\n",
      "        (1): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "        (2): UpConvBlock(\n",
      "          (conv_block): ConvBlock(\n",
      "            (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation): GELU()\n",
      "            (drop): Dropout(p=0.3, inplace=False)\n",
      "            (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "          )\n",
      "          (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "        )\n",
      "      )\n",
      "      (conv1x1_one): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------------------------------------\n",
      "            Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=============================================================================\n",
      "   AutoEncoder1D_Artur-1        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-2        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-3        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-4        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-5        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-6        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-7        [4, 1, 2048]          75,585          75,585\n",
      "   AutoEncoder1D_Artur-8        [4, 1, 2048]          75,585          75,585\n",
      "=============================================================================\n",
      "Total params: 604,680\n",
      "Trainable params: 604,680\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------------\n",
      "Starting Training of our model \n",
      "Number of samples 512 \n",
      "Size of batch: 16 Number batches 32\n",
      "................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 20 train loss_0 : -0.729 val loss_0 : 0.103 train loss_1 : 0.774 val loss_1 : 0.0912 train loss_2 : 0.45 val loss_2 : 1.94 train loss_3 : 5.24 val loss_3 : 8.62 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................................................................................\n",
      "Epoch 40 train loss_0 : -0.833 val loss_0 : 0.108 train loss_1 : 0.862 val loss_1 : 0.101 train loss_2 : 0.289 val loss_2 : 2.09 train loss_3 : 4.64 val loss_3 : 7.73 \n",
      "................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................\n",
      "Epoch 60 train loss_0 : -0.877 val loss_0 : 0.0781 train loss_1 : 0.897 val loss_1 : 0.135 train loss_2 : 0.205 val loss_2 : 2.13 train loss_3 : 4.41 val loss_3 : 7.65 \n",
      "................................................................................................................................................................................................................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................................................................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................................................................................\n",
      "Epoch 80 train loss_0 : -0.9 val loss_0 : 0.0817 train loss_1 : 0.917 val loss_1 : 0.125 train loss_2 : 0.169 val loss_2 : 2.07 train loss_3 : 4.21 val loss_3 : 7.33 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 100 train loss_0 : -0.916 val loss_0 : 0.0495 train loss_1 : 0.929 val loss_1 : 0.152 train loss_2 : 0.136 val loss_2 : 2.01 train loss_3 : 4.11 val loss_3 : 7.12 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 120 train loss_0 : -0.924 val loss_0 : 0.0591 train loss_1 : 0.937 val loss_1 : 0.142 train loss_2 : 0.129 val loss_2 : 2.01 train loss_3 : 4.02 val loss_3 : 7.13 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 140 train loss_0 : -0.929 val loss_0 : 0.0883 train loss_1 : 0.941 val loss_1 : 0.115 train loss_2 : 0.117 val loss_2 : 2.04 train loss_3 : 3.96 val loss_3 : 7.52 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 160 train loss_0 : -0.934 val loss_0 : 0.0724 train loss_1 : 0.945 val loss_1 : 0.137 train loss_2 : 0.109 val loss_2 : 2.09 train loss_3 : 3.86 val loss_3 : 7.51 \n",
      "................................................................................................................................................................(8, 5120)\n",
      "(8, 5120)\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 180 train loss_0 : -0.937 val loss_0 : 0.0832 train loss_1 : 0.948 val loss_1 : 0.121 train loss_2 : 0.102 val loss_2 : 2.05 train loss_3 : 3.81 val loss_3 : 7.21 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 200 train loss_0 : -0.941 val loss_0 : 0.124 train loss_1 : 0.95 val loss_1 : 0.0887 train loss_2 : 0.0968 val loss_2 : 2.13 train loss_3 : 3.87 val loss_3 : 7.25 \n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Epoch 220 train loss_0 : -0.944 val loss_0 : 0.0981 train loss_1 : 0.953 val loss_1 : 0.107 train loss_2 : 0.0917 val loss_2 : 2.05 train loss_3 : 3.7 val loss_3 : 7.27 \n",
      "..........................................................."
     ]
    }
   ],
   "source": [
    "n_runs = 3\n",
    "\n",
    "for i in range(n_runs):\n",
    "    \n",
    "    model = autoencoder_new_Artur.AutoEncoder1D_Artur_MultiHead(hp_autoencoder)\n",
    "\n",
    "    loss_func = train_utils.make_complex_loss_function(mse_weight = 0.1, \n",
    "                                                       corr_weight = 1,\n",
    "                                                       manifold_weight = 0,\n",
    "                                                       bound=1)\n",
    "    train_step = train_utils.train_step\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                       lr=config['lr'], \n",
    "                       weight_decay=config['weight_decay'])\n",
    "    \n",
    "    \n",
    "    parameters = {\n",
    "        'EPOCHS': 1500,\n",
    "        'model': model, \n",
    "        'train_loader': train_loader, \n",
    "        'val_loader': val_loader, \n",
    "        'loss_function': loss_func,\n",
    "        'train_step': train_step,\n",
    "        'optimizer': optimizer, \n",
    "        'device': 'cuda', \n",
    "        'raw_test_data': test_dataset_prep,\n",
    "        'show_info': 20, \n",
    "        'num_losses': 5,\n",
    "        'labels': labels_roi,\n",
    "        'inference_function': inference.model_inference_function, \n",
    "        'to_many': config['to_many']\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    path_to_save_wandb = 'common/koval_alvi/Checkpoints/wandb_brain'\n",
    "    \n",
    "    \n",
    "    with wandb.init(project=\"eeg_fmri\", config=config, save_code=True):\n",
    "        \n",
    "        wandb.define_metric(\"val/corr_mean\", summary=\"max\")\n",
    "\n",
    "        if i == 0: \n",
    "            exp_name = wandb.run.name\n",
    "        \n",
    "        wandb.run.name = exp_name +'_run_' + str(i)\n",
    "        \n",
    "        print(config)\n",
    "        print(parameters['model'])\n",
    "        print(summary(model, torch.zeros(4, config['n_channels'], config['WINDOW_SIZE']), show_input=False))\n",
    "        \n",
    "        model = train_utils.wanb_train_regression(**parameters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923ea3f-b6c9-495e-bea2-36552a50cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e40a09-12c2-43b9-957f-8b37d0a0daa8",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_torch",
   "language": "python",
   "name": "myenv_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
