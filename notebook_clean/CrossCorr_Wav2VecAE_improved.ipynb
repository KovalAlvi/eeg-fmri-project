{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57334e36-39bf-4342-ab23-5bf0868237b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab4de19-cc35-47c2-912c-d1dc3372c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv_torch/lib/python3.9/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys, os, json\n",
    "import mne, sklearn, wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from nilearn import datasets, image, masking, plotting\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "\n",
    "\n",
    "# animation part\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# from celluloid import Camera   # it is convinient method to animate\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "## torch libraries \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from pytorch_model_summary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68eacc99-823f-49be-80b1-b432a1833d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "from utils import get_datasets\n",
    "from utils import preproc\n",
    "from utils import torch_dataset\n",
    "from utils import train_utils\n",
    "from utils import inference\n",
    "from utils.models_arch import autoencoder_new, autoencoder_v3_separable, autoencoder_cross_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974b520-53af-4aae-8475-ad9864cc86f0",
   "metadata": {},
   "source": [
    "# Set all hyperparameters\n",
    "- Cuda and GPU.\n",
    "- Parameters of dataset. \n",
    "- random seed( if necessary). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9740a7b-6c36-471f-bafe-3361c4758086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)  # python operation seed\n",
    "np.random.seed(0)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68da9ec-be91-4cc8-b7d2-87c106d53ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(  \n",
    "                dataset_name = 'CWL', # CWL\n",
    "                new_fps=100, \n",
    "                freqs = np.logspace(np.log10(2), np.log10(99), 16), \n",
    "    \n",
    "                n_channels = 30, # 30 \n",
    "                n_roi = 6,\n",
    "                \n",
    "                bold_delay = 6,\n",
    "                to_many = True,\n",
    "                random_subsample = True,\n",
    "                sample_per_epoch = 512, \n",
    "                WINDOW_SIZE = 2048,\n",
    "                    \n",
    "                optimizer='adamW',\n",
    "                lr=3e-4,\n",
    "                weight_decay=3e-4, # 3e-4\n",
    "                batch_size=16, \n",
    "                \n",
    "                preproc_type = 'dB_log',\n",
    "                loss_function = 'mse_corr', \n",
    "                model_type = 'AE_CrossCorr_improved'\n",
    "                )\n",
    "\n",
    "\n",
    "hp_autoencoder = dict(n_electrodes=config['n_channels'],\n",
    "                     n_freqs = len(config['freqs']),\n",
    "                     n_channels_out=config['n_roi'],\n",
    "                     \n",
    "                     channels = [128, 128, 128, 64], \n",
    "                     kernel_sizes=[5, 5, 3], # kernel_sizes=[5, 5, 3]\n",
    "                     strides=[8, 8, 4], # strides=[8, 8, 4]\n",
    "                     dilation=[1, 1, 1], \n",
    "                     decoder_reduce=4, \n",
    "                     corr_proj_size = 64,\n",
    "                     window_cross_corr=512)\n",
    "\n",
    "\n",
    "config = {**hp_autoencoder, **config}\n",
    "\n",
    "params_train = {'batch_size': config['batch_size'],\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0}\n",
    "\n",
    "params_val = {'batch_size': config['batch_size'],\n",
    "              'shuffle': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a1c42-68f1-4afa-9943-02a441b15e07",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Upload preprocessed dataset from np files. \n",
    "It should accelerate speed of experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951efaec-ba20-48c9-94aa-588f3f5b13e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: (30, 16, 20590) (6, 20590)\n",
      "Size of test dataset: (30, 16, 5400) (6, 5400)\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/processed/labels_roi_6.json\", 'r') as f:\n",
    "    labels_roi = json.load(f)\n",
    "\n",
    "\n",
    "if config['dataset_name']=='CWL':\n",
    "    dataset_path = '../data/processed/CWL/trio1_100_hz_6_roi_2_99_freqs.npz'\n",
    "    \n",
    "elif config['dataset_name']=='NODDI':\n",
    "    dataset_path = '../data/processed/NODDI/32_100_hz_6_roi_2_99_freqs.npz'\n",
    "else:\n",
    "    print('no such dataset')\n",
    "\n",
    "\n",
    "# download data\n",
    "data = np.load(dataset_path)\n",
    "\n",
    "train_dataset_prep = (data['x_train'], data['y_train'])\n",
    "test_dataset_prep = (data['x_test'], data['y_test'])\n",
    "\n",
    "\n",
    "# apply time dealy corrected\n",
    "train_dataset_prep = preproc.bold_time_delay_align(train_dataset_prep, \n",
    "                                                   config['new_fps'],\n",
    "                                                   config['bold_delay'])\n",
    "test_dataset_prep = preproc.bold_time_delay_align(test_dataset_prep, \n",
    "                                                  config['new_fps'],\n",
    "                                                  config['bold_delay'])\n",
    "\n",
    "\n",
    "print('Size of train dataset:', train_dataset_prep[0].shape, train_dataset_prep[1].shape)\n",
    "print('Size of test dataset:', test_dataset_prep[0].shape, test_dataset_prep[1].shape)\n",
    "\n",
    "# torch dataset creation \n",
    "torch_dataset_train = torch_dataset.CreateDataset_eeg_fmri(train_dataset_prep, \n",
    "                                                            random_sample=config['random_subsample'], \n",
    "                                                            sample_per_epoch=config['sample_per_epoch'], \n",
    "                                                            to_many=config['to_many'], \n",
    "                                                            window_size = config['WINDOW_SIZE'])\n",
    "\n",
    "torch_dataset_test = torch_dataset.CreateDataset_eeg_fmri(test_dataset_prep, \n",
    "                                                            random_sample=False, \n",
    "                                                            sample_per_epoch=None, \n",
    "                                                            to_many=config['to_many'], \n",
    "                                                            window_size = config['WINDOW_SIZE'])\n",
    "\n",
    "# because you do not have strid for val data. \n",
    "torch_dataset_test = Subset(torch_dataset_test, np.arange(len(torch_dataset_test))[::100])\n",
    "\n",
    "# init dataloaders for training\n",
    "train_loader = torch.utils.data.DataLoader(torch_dataset_train, **params_train)\n",
    "val_loader = torch.utils.data.DataLoader(torch_dataset_test, **params_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f97bc-6319-4183-9845-9882afce19d2",
   "metadata": {},
   "source": [
    "## Model investigation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff0863-786a-4c24-9130-c997833869c1",
   "metadata": {},
   "source": [
    "# Init Model, Loss, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd255921-d8d2-4d66-b77b-395ad97cec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels for decoder [ 32  32  32 128]\n",
      "Input size:  torch.Size([4, 30, 16, 1024])\n",
      "Output size:  torch.Size([4, 6, 1024])\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv1d-1        [4, 6960, 2]         445,504         445,504\n",
      "         Dropout-2          [4, 64, 2]               0               0\n",
      "            ReLU-3          [4, 64, 2]               0               0\n",
      "       ConvBlock-4      [4, 480, 1024]         184,576         184,576\n",
      "       ConvBlock-5      [4, 128, 1024]          82,176          82,176\n",
      "       ConvBlock-6       [4, 128, 128]          82,176          82,176\n",
      "       ConvBlock-7        [4, 128, 16]          24,704          24,704\n",
      "       ConvBlock-8         [4, 128, 4]          16,640          16,640\n",
      "     UpConvBlock-9         [4, 128, 4]          12,352          12,352\n",
      "    UpConvBlock-10         [4, 32, 16]           5,184           5,184\n",
      "    UpConvBlock-11        [4, 32, 128]           5,184           5,184\n",
      "         Conv1d-12       [4, 32, 1024]             198             198\n",
      "=======================================================================\n",
      "Total params: 858,694\n",
      "Trainable params: 858,694\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder_cross_corr.CrossCorrAutoEncoder1D(**hp_autoencoder)\n",
    "\n",
    "x = torch.zeros(4, 30, 16, 1024)\n",
    "print('Input size: ', x.shape)\n",
    "print('Output size: ',model(x).shape)\n",
    "print('')\n",
    "\n",
    "print(summary(model, x, show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e4982-344f-4d44-8d7e-445f4c4a5662",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d21727-423a-4872-8bec-82fbd3b4fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels for decoder [ 32  32  32 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkoval_alvi\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/koval_alvi/eeg_fmri/runs/2gvge4j1\" target=\"_blank\">deft-serenity-343</a></strong> to <a href=\"https://wandb.ai/koval_alvi/eeg_fmri\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_electrodes': 30, 'n_freqs': 16, 'n_channels_out': 6, 'channels': [128, 128, 128, 64], 'kernel_sizes': [5, 5, 3], 'strides': [8, 8, 4], 'dilation': [1, 1, 1], 'decoder_reduce': 4, 'corr_proj_size': 64, 'window_cross_corr': 512, 'dataset_name': 'CWL', 'new_fps': 100, 'freqs': array([ 2.        ,  2.59420132,  3.36494024,  4.3646662 ,  5.6614114 ,\n",
      "        7.34342046,  9.52515552, 12.3550855 , 16.02578954, 20.78706217,\n",
      "       26.96291204, 34.97361097, 45.36429384, 58.84205542, 76.32406886,\n",
      "       99.        ]), 'n_channels': 30, 'n_roi': 6, 'bold_delay': 6, 'to_many': True, 'random_subsample': True, 'sample_per_epoch': 512, 'WINDOW_SIZE': 2048, 'optimizer': 'adamW', 'lr': 0.0003, 'weight_decay': 0.0003, 'batch_size': 16, 'preproc_type': 'dB_log', 'loss_function': 'mse_corr', 'model_type': 'AE_CrossCorr_improved'}\n",
      "CrossCorrAutoEncoder1D(\n",
      "  (project): Sequential(\n",
      "    (0): Conv1d(6960, 64, kernel_size=(1,), stride=(1,))\n",
      "    (1): Dropout(p=0.25, inplace=False)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (spatial_reduce): ConvBlock(\n",
      "    (conv1d): Conv1d(480, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (activation): GELU()\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (encoder): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1d): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELU()\n",
      "      (drop): Dropout(p=0.3, inplace=False)\n",
      "      (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1d): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELU()\n",
      "      (drop): Dropout(p=0.3, inplace=False)\n",
      "      (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELU()\n",
      "      (drop): Dropout(p=0.3, inplace=False)\n",
      "      (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (mapping): ConvBlock(\n",
      "    (conv1d): Conv1d(128, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (activation): GELU()\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): UpConvBlock(\n",
      "      (conv_block): ConvBlock(\n",
      "        (conv1d): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "    )\n",
      "    (1): UpConvBlock(\n",
      "      (conv_block): ConvBlock(\n",
      "        (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "    )\n",
      "    (2): UpConvBlock(\n",
      "      (conv_block): ConvBlock(\n",
      "        (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "    )\n",
      "  )\n",
      "  (conv1x1_one): Conv1d(32, 6, kernel_size=(1,), stride=(1,), padding=same)\n",
      ")\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv1d-1        [4, 6960, 4]         445,504         445,504\n",
      "         Dropout-2          [4, 64, 4]               0               0\n",
      "            ReLU-3          [4, 64, 4]               0               0\n",
      "       ConvBlock-4      [4, 480, 2048]         184,576         184,576\n",
      "       ConvBlock-5      [4, 128, 2048]          82,176          82,176\n",
      "       ConvBlock-6       [4, 128, 256]          82,176          82,176\n",
      "       ConvBlock-7        [4, 128, 32]          24,704          24,704\n",
      "       ConvBlock-8         [4, 128, 8]          16,640          16,640\n",
      "     UpConvBlock-9         [4, 128, 8]          12,352          12,352\n",
      "    UpConvBlock-10         [4, 32, 32]           5,184           5,184\n",
      "    UpConvBlock-11        [4, 32, 256]           5,184           5,184\n",
      "         Conv1d-12       [4, 32, 2048]             198             198\n",
      "=======================================================================\n",
      "Total params: 858,694\n",
      "Trainable params: 858,694\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "Starting Training of our model \n",
      "Number of samples 512 \n",
      "Size of batch: 16 Number batches 32\n",
      "................................................................................................................................................................\n",
      "Epoch 5 train loss_0 : -0.546 val loss_0 : -0.257 train loss_1 : 0.609 val loss_1 : 0.384 train loss_2 : 0.634 val loss_2 : 1.28 train loss_3 : 4.65 val loss_3 : 10.1 \n",
      "................................................................................................................................................................\n",
      "Epoch 10 train loss_0 : -0.706 val loss_0 : -0.336 train loss_1 : 0.751 val loss_1 : 0.459 train loss_2 : 0.457 val loss_2 : 1.23 train loss_3 : 4.18 val loss_3 : 8.76 \n",
      "................................................................................................................................................................\n",
      "Epoch 15 train loss_0 : -0.776 val loss_0 : -0.359 train loss_1 : 0.813 val loss_1 : 0.478 train loss_2 : 0.374 val loss_2 : 1.18 train loss_3 : 4.03 val loss_3 : 8.36 \n",
      "................................................................................................................................................................\n",
      "Epoch 20 train loss_0 : -0.796 val loss_0 : -0.303 train loss_1 : 0.828 val loss_1 : 0.438 train loss_2 : 0.324 val loss_2 : 1.35 train loss_3 : 3.85 val loss_3 : 8.04 \n",
      "................................................................................................................................................................\n",
      "Epoch 25 train loss_0 : -0.82 val loss_0 : -0.286 train loss_1 : 0.85 val loss_1 : 0.417 train loss_2 : 0.301 val loss_2 : 1.31 train loss_3 : 3.74 val loss_3 : 6.96 \n",
      "................................................................................................................................................................\n",
      "Epoch 30 train loss_0 : -0.827 val loss_0 : -0.243 train loss_1 : 0.855 val loss_1 : 0.384 train loss_2 : 0.28 val loss_2 : 1.4 train loss_3 : 3.66 val loss_3 : 7.71 \n",
      "................................................................................................................................................................\n",
      "Epoch 35 train loss_0 : -0.836 val loss_0 : -0.208 train loss_1 : 0.863 val loss_1 : 0.349 train loss_2 : 0.268 val loss_2 : 1.41 train loss_3 : 3.58 val loss_3 : 7.47 \n",
      "................................................................................................................................................................\n",
      "Epoch 40 train loss_0 : -0.842 val loss_0 : -0.218 train loss_1 : 0.868 val loss_1 : 0.35 train loss_2 : 0.262 val loss_2 : 1.32 train loss_3 : 3.4 val loss_3 : 7.51 \n",
      "................................................................................................................................................................\n",
      "Epoch 45 train loss_0 : -0.854 val loss_0 : -0.254 train loss_1 : 0.879 val loss_1 : 0.381 train loss_2 : 0.249 val loss_2 : 1.27 train loss_3 : 3.26 val loss_3 : 6.88 \n",
      "................................................................................................................................................................\n",
      "Epoch 50 train loss_0 : -0.86 val loss_0 : -0.223 train loss_1 : 0.884 val loss_1 : 0.364 train loss_2 : 0.234 val loss_2 : 1.41 train loss_3 : 3.07 val loss_3 : 6.73 \n",
      "................................................................................................................................................................\n",
      "Epoch 55 train loss_0 : -0.861 val loss_0 : -0.229 train loss_1 : 0.885 val loss_1 : 0.367 train loss_2 : 0.235 val loss_2 : 1.38 train loss_3 : 2.97 val loss_3 : 7.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 60 train loss_0 : -0.865 val loss_0 : -0.211 train loss_1 : 0.887 val loss_1 : 0.346 train loss_2 : 0.227 val loss_2 : 1.35 train loss_3 : 2.89 val loss_3 : 6.77 \n",
      "................................................................................................................................................................\n",
      "Epoch 65 train loss_0 : -0.867 val loss_0 : -0.191 train loss_1 : 0.889 val loss_1 : 0.335 train loss_2 : 0.219 val loss_2 : 1.44 train loss_3 : 2.78 val loss_3 : 6.06 \n",
      "................................................................................................................................................................\n",
      "Epoch 70 train loss_0 : -0.871 val loss_0 : -0.167 train loss_1 : 0.893 val loss_1 : 0.315 train loss_2 : 0.219 val loss_2 : 1.48 train loss_3 : 2.69 val loss_3 : 6.4 \n",
      "................................................................................................................................................................\n",
      "Epoch 75 train loss_0 : -0.874 val loss_0 : -0.18 train loss_1 : 0.895 val loss_1 : 0.328 train loss_2 : 0.212 val loss_2 : 1.48 train loss_3 : 2.62 val loss_3 : 6.54 \n",
      "................................................................................................................................................................\n",
      "Epoch 80 train loss_0 : -0.877 val loss_0 : -0.179 train loss_1 : 0.898 val loss_1 : 0.326 train loss_2 : 0.206 val loss_2 : 1.47 train loss_3 : 2.58 val loss_3 : 7.24 \n",
      "................................................................................................................................................................\n",
      "Epoch 85 train loss_0 : -0.878 val loss_0 : -0.166 train loss_1 : 0.899 val loss_1 : 0.312 train loss_2 : 0.209 val loss_2 : 1.46 train loss_3 : 2.51 val loss_3 : 5.94 \n",
      "................................................................................................................................................................\n",
      "Epoch 90 train loss_0 : -0.881 val loss_0 : -0.191 train loss_1 : 0.901 val loss_1 : 0.331 train loss_2 : 0.198 val loss_2 : 1.4 train loss_3 : 2.46 val loss_3 : 5.91 \n",
      "................................................................................................................................................................\n",
      "Epoch 95 train loss_0 : -0.884 val loss_0 : -0.236 train loss_1 : 0.903 val loss_1 : 0.364 train loss_2 : 0.193 val loss_2 : 1.28 train loss_3 : 2.42 val loss_3 : 6.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 100 train loss_0 : -0.885 val loss_0 : -0.224 train loss_1 : 0.905 val loss_1 : 0.363 train loss_2 : 0.195 val loss_2 : 1.39 train loss_3 : 2.42 val loss_3 : 6.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 105 train loss_0 : -0.886 val loss_0 : -0.2 train loss_1 : 0.905 val loss_1 : 0.335 train loss_2 : 0.194 val loss_2 : 1.35 train loss_3 : 2.33 val loss_3 : 6.02 \n",
      "................................................................................................................................................................\n",
      "Epoch 110 train loss_0 : -0.886 val loss_0 : -0.224 train loss_1 : 0.905 val loss_1 : 0.362 train loss_2 : 0.191 val loss_2 : 1.38 train loss_3 : 2.28 val loss_3 : 6.47 \n",
      "................................................................................................................................................................\n",
      "Epoch 115 train loss_0 : -0.889 val loss_0 : -0.264 train loss_1 : 0.908 val loss_1 : 0.401 train loss_2 : 0.19 val loss_2 : 1.37 train loss_3 : 2.27 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 120 train loss_0 : -0.893 val loss_0 : -0.234 train loss_1 : 0.912 val loss_1 : 0.371 train loss_2 : 0.188 val loss_2 : 1.37 train loss_3 : 2.18 val loss_3 : 6.73 \n",
      "................................................................................................................................................................\n",
      "Epoch 125 train loss_0 : -0.892 val loss_0 : -0.287 train loss_1 : 0.911 val loss_1 : 0.419 train loss_2 : 0.187 val loss_2 : 1.31 train loss_3 : 2.2 val loss_3 : 6.31 \n",
      "................................................................................................................................................................\n",
      "Epoch 130 train loss_0 : -0.892 val loss_0 : -0.192 train loss_1 : 0.911 val loss_1 : 0.33 train loss_2 : 0.182 val loss_2 : 1.38 train loss_3 : 2.14 val loss_3 : 6.02 \n",
      "................................................................................................................................................................\n",
      "Epoch 135 train loss_0 : -0.894 val loss_0 : -0.231 train loss_1 : 0.912 val loss_1 : 0.37 train loss_2 : 0.18 val loss_2 : 1.39 train loss_3 : 2.17 val loss_3 : 5.95 \n",
      "................................................................................................................................................................\n",
      "Epoch 140 train loss_0 : -0.894 val loss_0 : -0.197 train loss_1 : 0.912 val loss_1 : 0.345 train loss_2 : 0.179 val loss_2 : 1.48 train loss_3 : 2.11 val loss_3 : 6.55 \n",
      "................................................................................................................................................................\n",
      "Epoch 145 train loss_0 : -0.896 val loss_0 : -0.281 train loss_1 : 0.914 val loss_1 : 0.411 train loss_2 : 0.176 val loss_2 : 1.29 train loss_3 : 2.12 val loss_3 : 6.15 \n",
      "................................................................................................................................................................\n",
      "Epoch 150 train loss_0 : -0.898 val loss_0 : -0.248 train loss_1 : 0.916 val loss_1 : 0.382 train loss_2 : 0.171 val loss_2 : 1.34 train loss_3 : 2.08 val loss_3 : 6.54 \n",
      "................................................................................................................................................................\n",
      "Epoch 155 train loss_0 : -0.897 val loss_0 : -0.185 train loss_1 : 0.915 val loss_1 : 0.339 train loss_2 : 0.176 val loss_2 : 1.54 train loss_3 : 2.09 val loss_3 : 6.31 \n",
      "................................................................................................................................................................\n",
      "Epoch 160 train loss_0 : -0.898 val loss_0 : -0.184 train loss_1 : 0.915 val loss_1 : 0.324 train loss_2 : 0.172 val loss_2 : 1.4 train loss_3 : 2.03 val loss_3 : 5.86 \n",
      "................................................................................................................................................................\n",
      "Epoch 165 train loss_0 : -0.897 val loss_0 : -0.251 train loss_1 : 0.914 val loss_1 : 0.385 train loss_2 : 0.171 val loss_2 : 1.34 train loss_3 : 2.04 val loss_3 : 6.14 \n",
      "................................................................................................................................................................\n",
      "Epoch 170 train loss_0 : -0.898 val loss_0 : -0.214 train loss_1 : 0.916 val loss_1 : 0.366 train loss_2 : 0.171 val loss_2 : 1.52 train loss_3 : 2.02 val loss_3 : 5.71 \n",
      "................................................................................................................................................................\n",
      "Epoch 175 train loss_0 : -0.9 val loss_0 : -0.209 train loss_1 : 0.917 val loss_1 : 0.352 train loss_2 : 0.166 val loss_2 : 1.43 train loss_3 : 1.99 val loss_3 : 6.04 \n",
      "................................................................................................................................................................\n",
      "Epoch 180 train loss_0 : -0.901 val loss_0 : -0.288 train loss_1 : 0.918 val loss_1 : 0.411 train loss_2 : 0.169 val loss_2 : 1.23 train loss_3 : 2.01 val loss_3 : 5.82 \n",
      "................................................................................................................................................................\n",
      "Epoch 185 train loss_0 : -0.9 val loss_0 : -0.288 train loss_1 : 0.917 val loss_1 : 0.418 train loss_2 : 0.168 val loss_2 : 1.3 train loss_3 : 2.0 val loss_3 : 6.35 \n",
      "................................................................................................................................................................\n",
      "Epoch 190 train loss_0 : -0.901 val loss_0 : -0.324 train loss_1 : 0.917 val loss_1 : 0.458 train loss_2 : 0.168 val loss_2 : 1.34 train loss_3 : 2.01 val loss_3 : 5.71 \n",
      "................................................................................................................................................................\n",
      "Epoch 195 train loss_0 : -0.9 val loss_0 : -0.36 train loss_1 : 0.916 val loss_1 : 0.474 train loss_2 : 0.17 val loss_2 : 1.14 train loss_3 : 2.0 val loss_3 : 5.69 \n",
      "................................................................................................................................................................\n",
      "Epoch 200 train loss_0 : -0.903 val loss_0 : -0.268 train loss_1 : 0.92 val loss_1 : 0.403 train loss_2 : 0.166 val loss_2 : 1.35 train loss_3 : 1.98 val loss_3 : 5.44 \n",
      "................................................................................................................................................................\n",
      "Epoch 205 train loss_0 : -0.901 val loss_0 : -0.27 train loss_1 : 0.917 val loss_1 : 0.399 train loss_2 : 0.165 val loss_2 : 1.29 train loss_3 : 1.99 val loss_3 : 5.3 \n",
      "................................................................................................................................................................\n",
      "Epoch 210 train loss_0 : -0.902 val loss_0 : -0.197 train loss_1 : 0.918 val loss_1 : 0.348 train loss_2 : 0.164 val loss_2 : 1.51 train loss_3 : 1.97 val loss_3 : 5.97 \n",
      "................................................................................................................................................................\n",
      "Epoch 215 train loss_0 : -0.902 val loss_0 : -0.252 train loss_1 : 0.919 val loss_1 : 0.383 train loss_2 : 0.167 val loss_2 : 1.3 train loss_3 : 1.98 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 220 train loss_0 : -0.903 val loss_0 : -0.307 train loss_1 : 0.919 val loss_1 : 0.439 train loss_2 : 0.16 val loss_2 : 1.32 train loss_3 : 1.95 val loss_3 : 5.27 \n",
      "................................................................................................................................................................\n",
      "Epoch 225 train loss_0 : -0.903 val loss_0 : -0.19 train loss_1 : 0.919 val loss_1 : 0.349 train loss_2 : 0.166 val loss_2 : 1.59 train loss_3 : 1.95 val loss_3 : 6.12 \n",
      "................................................................................................................................................................\n",
      "Epoch 230 train loss_0 : -0.904 val loss_0 : -0.206 train loss_1 : 0.92 val loss_1 : 0.364 train loss_2 : 0.16 val loss_2 : 1.58 train loss_3 : 1.96 val loss_3 : 5.76 \n",
      "................................................................................................................................................................\n",
      "Epoch 235 train loss_0 : -0.902 val loss_0 : -0.35 train loss_1 : 0.918 val loss_1 : 0.478 train loss_2 : 0.16 val loss_2 : 1.27 train loss_3 : 1.95 val loss_3 : 6.18 \n",
      "................................................................................................................................................................\n",
      "Epoch 240 train loss_0 : -0.903 val loss_0 : -0.253 train loss_1 : 0.92 val loss_1 : 0.394 train loss_2 : 0.164 val loss_2 : 1.41 train loss_3 : 1.96 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 245 train loss_0 : -0.903 val loss_0 : -0.333 train loss_1 : 0.92 val loss_1 : 0.454 train loss_2 : 0.164 val loss_2 : 1.21 train loss_3 : 1.94 val loss_3 : 6.07 \n",
      "................................................................................................................................................................\n",
      "Epoch 250 train loss_0 : -0.905 val loss_0 : -0.273 train loss_1 : 0.921 val loss_1 : 0.409 train loss_2 : 0.159 val loss_2 : 1.36 train loss_3 : 1.92 val loss_3 : 5.32 \n",
      "................................................................................................................................................................\n",
      "Epoch 255 train loss_0 : -0.904 val loss_0 : -0.302 train loss_1 : 0.92 val loss_1 : 0.433 train loss_2 : 0.16 val loss_2 : 1.31 train loss_3 : 1.91 val loss_3 : 5.04 \n",
      "................................................................................................................................................................\n",
      "Epoch 260 train loss_0 : -0.904 val loss_0 : -0.268 train loss_1 : 0.92 val loss_1 : 0.4 train loss_2 : 0.162 val loss_2 : 1.32 train loss_3 : 1.9 val loss_3 : 6.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 265 train loss_0 : -0.906 val loss_0 : -0.254 train loss_1 : 0.922 val loss_1 : 0.39 train loss_2 : 0.161 val loss_2 : 1.37 train loss_3 : 1.92 val loss_3 : 5.81 \n",
      "................................................................................................................................................................\n",
      "Epoch 270 train loss_0 : -0.905 val loss_0 : -0.328 train loss_1 : 0.921 val loss_1 : 0.446 train loss_2 : 0.159 val loss_2 : 1.18 train loss_3 : 1.92 val loss_3 : 5.53 \n",
      "................................................................................................................................................................\n",
      "Epoch 275 train loss_0 : -0.906 val loss_0 : -0.301 train loss_1 : 0.922 val loss_1 : 0.433 train loss_2 : 0.156 val loss_2 : 1.32 train loss_3 : 1.89 val loss_3 : 5.24 \n",
      "................................................................................................................................................................\n",
      "Epoch 280 train loss_0 : -0.906 val loss_0 : -0.322 train loss_1 : 0.922 val loss_1 : 0.448 train loss_2 : 0.155 val loss_2 : 1.26 train loss_3 : 1.9 val loss_3 : 5.59 \n",
      "................................................................................................................................................................\n",
      "Epoch 285 train loss_0 : -0.905 val loss_0 : -0.19 train loss_1 : 0.921 val loss_1 : 0.337 train loss_2 : 0.161 val loss_2 : 1.47 train loss_3 : 1.91 val loss_3 : 5.81 \n",
      "................................................................................................................................................................\n",
      "Epoch 290 train loss_0 : -0.906 val loss_0 : -0.25 train loss_1 : 0.922 val loss_1 : 0.388 train loss_2 : 0.157 val loss_2 : 1.37 train loss_3 : 1.9 val loss_3 : 4.91 \n",
      "................................................................................................................................................................\n",
      "Epoch 295 train loss_0 : -0.907 val loss_0 : -0.224 train loss_1 : 0.922 val loss_1 : 0.369 train loss_2 : 0.155 val loss_2 : 1.45 train loss_3 : 1.87 val loss_3 : 5.98 \n",
      "................................................................................................................................................................\n",
      "Epoch 300 train loss_0 : -0.907 val loss_0 : -0.372 train loss_1 : 0.923 val loss_1 : 0.484 train loss_2 : 0.16 val loss_2 : 1.13 train loss_3 : 1.9 val loss_3 : 5.56 \n",
      "................................................................................................................................................................\n",
      "Epoch 305 train loss_0 : -0.909 val loss_0 : -0.284 train loss_1 : 0.925 val loss_1 : 0.416 train loss_2 : 0.159 val loss_2 : 1.32 train loss_3 : 1.94 val loss_3 : 5.57 \n",
      "................................................................................................................................................................\n",
      "Epoch 310 train loss_0 : -0.907 val loss_0 : -0.204 train loss_1 : 0.923 val loss_1 : 0.345 train loss_2 : 0.159 val loss_2 : 1.4 train loss_3 : 1.91 val loss_3 : 5.43 \n",
      "................................................................................................................................................................\n",
      "Epoch 315 train loss_0 : -0.907 val loss_0 : -0.278 train loss_1 : 0.923 val loss_1 : 0.408 train loss_2 : 0.156 val loss_2 : 1.3 train loss_3 : 1.9 val loss_3 : 5.37 \n",
      "................................................................................................................................................................\n",
      "Epoch 320 train loss_0 : -0.904 val loss_0 : -0.367 train loss_1 : 0.92 val loss_1 : 0.484 train loss_2 : 0.158 val loss_2 : 1.17 train loss_3 : 1.93 val loss_3 : 5.46 \n",
      "................................................................................................................................................................\n",
      "Epoch 325 train loss_0 : -0.907 val loss_0 : -0.175 train loss_1 : 0.922 val loss_1 : 0.329 train loss_2 : 0.155 val loss_2 : 1.54 train loss_3 : 1.87 val loss_3 : 5.19 \n",
      "................................................................................................................................................................\n",
      "Epoch 330 train loss_0 : -0.907 val loss_0 : -0.39 train loss_1 : 0.923 val loss_1 : 0.51 train loss_2 : 0.156 val loss_2 : 1.2 train loss_3 : 1.89 val loss_3 : 5.48 \n",
      "................................................................................................................................................................\n",
      "Epoch 335 train loss_0 : -0.907 val loss_0 : -0.323 train loss_1 : 0.923 val loss_1 : 0.452 train loss_2 : 0.158 val loss_2 : 1.29 train loss_3 : 1.88 val loss_3 : 5.03 \n",
      "................................................................................................................................................................\n",
      "Epoch 340 train loss_0 : -0.907 val loss_0 : -0.232 train loss_1 : 0.923 val loss_1 : 0.367 train loss_2 : 0.154 val loss_2 : 1.35 train loss_3 : 1.87 val loss_3 : 5.46 \n",
      "................................................................................................................................................................\n",
      "Epoch 345 train loss_0 : -0.907 val loss_0 : -0.225 train loss_1 : 0.922 val loss_1 : 0.374 train loss_2 : 0.157 val loss_2 : 1.49 train loss_3 : 1.9 val loss_3 : 5.56 \n",
      "................................................................................................................................................................\n",
      "Epoch 350 train loss_0 : -0.908 val loss_0 : -0.203 train loss_1 : 0.923 val loss_1 : 0.372 train loss_2 : 0.155 val loss_2 : 1.69 train loss_3 : 1.87 val loss_3 : 5.24 \n",
      "................................................................................................................................................................\n",
      "Epoch 355 train loss_0 : -0.907 val loss_0 : -0.369 train loss_1 : 0.922 val loss_1 : 0.495 train loss_2 : 0.153 val loss_2 : 1.25 train loss_3 : 1.87 val loss_3 : 5.35 \n",
      "................................................................................................................................................................\n",
      "Epoch 360 train loss_0 : -0.908 val loss_0 : -0.3 train loss_1 : 0.923 val loss_1 : 0.436 train loss_2 : 0.156 val loss_2 : 1.36 train loss_3 : 1.89 val loss_3 : 4.96 \n",
      "................................................................................................................................................................\n",
      "Epoch 365 train loss_0 : -0.909 val loss_0 : -0.194 train loss_1 : 0.924 val loss_1 : 0.346 train loss_2 : 0.156 val loss_2 : 1.52 train loss_3 : 1.85 val loss_3 : 5.26 \n",
      "................................................................................................................................................................\n",
      "Epoch 370 train loss_0 : -0.908 val loss_0 : -0.212 train loss_1 : 0.924 val loss_1 : 0.349 train loss_2 : 0.154 val loss_2 : 1.36 train loss_3 : 1.85 val loss_3 : 5.44 \n",
      "................................................................................................................................................................\n",
      "Epoch 375 train loss_0 : -0.908 val loss_0 : -0.237 train loss_1 : 0.924 val loss_1 : 0.375 train loss_2 : 0.158 val loss_2 : 1.38 train loss_3 : 1.87 val loss_3 : 5.62 \n",
      "................................................................................................................................................................\n",
      "Epoch 380 train loss_0 : -0.909 val loss_0 : -0.25 train loss_1 : 0.924 val loss_1 : 0.385 train loss_2 : 0.15 val loss_2 : 1.35 train loss_3 : 1.86 val loss_3 : 5.36 \n",
      "................................................................................................................................................................\n",
      "Epoch 385 train loss_0 : -0.909 val loss_0 : -0.187 train loss_1 : 0.924 val loss_1 : 0.337 train loss_2 : 0.153 val loss_2 : 1.5 train loss_3 : 1.84 val loss_3 : 5.36 \n",
      "................................................................................................................................................................\n",
      "Epoch 390 train loss_0 : -0.908 val loss_0 : -0.238 train loss_1 : 0.923 val loss_1 : 0.392 train loss_2 : 0.155 val loss_2 : 1.54 train loss_3 : 1.88 val loss_3 : 6.41 \n",
      "................................................................................................................................................................\n",
      "Epoch 395 train loss_0 : -0.909 val loss_0 : -0.28 train loss_1 : 0.924 val loss_1 : 0.409 train loss_2 : 0.154 val loss_2 : 1.3 train loss_3 : 1.84 val loss_3 : 5.22 \n",
      "................................................................................................................................................................\n",
      "Epoch 400 train loss_0 : -0.909 val loss_0 : -0.253 train loss_1 : 0.924 val loss_1 : 0.394 train loss_2 : 0.156 val loss_2 : 1.41 train loss_3 : 1.87 val loss_3 : 5.36 \n",
      "................................................................................................................................................................\n",
      "Epoch 405 train loss_0 : -0.909 val loss_0 : -0.316 train loss_1 : 0.925 val loss_1 : 0.448 train loss_2 : 0.155 val loss_2 : 1.32 train loss_3 : 1.84 val loss_3 : 5.31 \n",
      "................................................................................................................................................................\n",
      "Epoch 410 train loss_0 : -0.909 val loss_0 : -0.308 train loss_1 : 0.925 val loss_1 : 0.448 train loss_2 : 0.155 val loss_2 : 1.4 train loss_3 : 1.86 val loss_3 : 5.74 \n",
      "................................................................................................................................................................\n",
      "Epoch 415 train loss_0 : -0.909 val loss_0 : -0.189 train loss_1 : 0.925 val loss_1 : 0.349 train loss_2 : 0.151 val loss_2 : 1.6 train loss_3 : 1.85 val loss_3 : 4.83 \n",
      "................................................................................................................................................................\n",
      "Epoch 420 train loss_0 : -0.909 val loss_0 : -0.174 train loss_1 : 0.925 val loss_1 : 0.323 train loss_2 : 0.154 val loss_2 : 1.49 train loss_3 : 1.86 val loss_3 : 5.11 \n",
      "................................................................................................................................................................\n",
      "Epoch 425 train loss_0 : -0.909 val loss_0 : -0.279 train loss_1 : 0.924 val loss_1 : 0.414 train loss_2 : 0.154 val loss_2 : 1.35 train loss_3 : 1.85 val loss_3 : 5.18 \n",
      "................................................................................................................................................................\n",
      "Epoch 430 train loss_0 : -0.908 val loss_0 : -0.223 train loss_1 : 0.924 val loss_1 : 0.367 train loss_2 : 0.155 val loss_2 : 1.44 train loss_3 : 1.86 val loss_3 : 5.68 \n",
      "................................................................................................................................................................\n",
      "Epoch 435 train loss_0 : -0.91 val loss_0 : -0.228 train loss_1 : 0.925 val loss_1 : 0.367 train loss_2 : 0.153 val loss_2 : 1.39 train loss_3 : 1.83 val loss_3 : 5.74 \n",
      "................................................................................................................................................................\n",
      "Epoch 440 train loss_0 : -0.91 val loss_0 : -0.229 train loss_1 : 0.925 val loss_1 : 0.377 train loss_2 : 0.15 val loss_2 : 1.48 train loss_3 : 1.82 val loss_3 : 4.92 \n",
      "................................................................................................................................................................\n",
      "Epoch 445 train loss_0 : -0.911 val loss_0 : -0.268 train loss_1 : 0.926 val loss_1 : 0.396 train loss_2 : 0.152 val loss_2 : 1.28 train loss_3 : 1.85 val loss_3 : 5.07 \n",
      "................................................................................................................................................................\n",
      "Epoch 450 train loss_0 : -0.91 val loss_0 : -0.2 train loss_1 : 0.925 val loss_1 : 0.345 train loss_2 : 0.146 val loss_2 : 1.46 train loss_3 : 1.83 val loss_3 : 5.25 \n",
      "................................................................................................................................................................\n",
      "Epoch 455 train loss_0 : -0.91 val loss_0 : -0.29 train loss_1 : 0.925 val loss_1 : 0.429 train loss_2 : 0.151 val loss_2 : 1.39 train loss_3 : 1.87 val loss_3 : 5.21 \n",
      "................................................................................................................................................................\n",
      "Epoch 460 train loss_0 : -0.91 val loss_0 : -0.25 train loss_1 : 0.925 val loss_1 : 0.395 train loss_2 : 0.15 val loss_2 : 1.46 train loss_3 : 1.84 val loss_3 : 5.17 \n",
      "................................................................................................................................................................\n",
      "Epoch 465 train loss_0 : -0.908 val loss_0 : -0.218 train loss_1 : 0.923 val loss_1 : 0.367 train loss_2 : 0.152 val loss_2 : 1.5 train loss_3 : 1.84 val loss_3 : 4.84 \n",
      "................................................................................................................................................................\n",
      "Epoch 470 train loss_0 : -0.909 val loss_0 : -0.195 train loss_1 : 0.924 val loss_1 : 0.354 train loss_2 : 0.151 val loss_2 : 1.58 train loss_3 : 1.83 val loss_3 : 4.97 \n",
      "................................................................................................................................................................\n",
      "Epoch 475 train loss_0 : -0.909 val loss_0 : -0.268 train loss_1 : 0.924 val loss_1 : 0.406 train loss_2 : 0.152 val loss_2 : 1.37 train loss_3 : 1.83 val loss_3 : 5.19 \n",
      "................................................................................................................................................................\n",
      "Epoch 480 train loss_0 : -0.91 val loss_0 : -0.314 train loss_1 : 0.925 val loss_1 : 0.442 train loss_2 : 0.148 val loss_2 : 1.28 train loss_3 : 1.82 val loss_3 : 5.44 \n",
      "................................................................................................................................................................\n",
      "Epoch 485 train loss_0 : -0.91 val loss_0 : -0.171 train loss_1 : 0.925 val loss_1 : 0.342 train loss_2 : 0.151 val loss_2 : 1.71 train loss_3 : 1.83 val loss_3 : 4.59 \n",
      ".............................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................\n",
      "Epoch 490 train loss_0 : -0.911 val loss_0 : -0.324 train loss_1 : 0.926 val loss_1 : 0.454 train loss_2 : 0.151 val loss_2 : 1.29 train loss_3 : 1.82 val loss_3 : 5.18 \n",
      "................................................................................................................................................................\n",
      "Epoch 495 train loss_0 : -0.91 val loss_0 : -0.24 train loss_1 : 0.925 val loss_1 : 0.382 train loss_2 : 0.149 val loss_2 : 1.42 train loss_3 : 1.83 val loss_3 : 5.36 \n",
      "................................................................................................................................................................\n",
      "Epoch 500 train loss_0 : -0.911 val loss_0 : -0.201 train loss_1 : 0.926 val loss_1 : 0.359 train loss_2 : 0.15 val loss_2 : 1.58 train loss_3 : 1.81 val loss_3 : 5.25 \n",
      "................................................................................................................................................................\n",
      "Epoch 505 train loss_0 : -0.908 val loss_0 : -0.136 train loss_1 : 0.923 val loss_1 : 0.32 train loss_2 : 0.152 val loss_2 : 1.84 train loss_3 : 1.85 val loss_3 : 5.23 \n",
      "................................................................................................................................................................\n",
      "Epoch 510 train loss_0 : -0.909 val loss_0 : -0.289 train loss_1 : 0.924 val loss_1 : 0.417 train loss_2 : 0.153 val loss_2 : 1.28 train loss_3 : 1.82 val loss_3 : 5.03 \n",
      "................................................................................................................................................................\n",
      "Epoch 515 train loss_0 : -0.91 val loss_0 : -0.267 train loss_1 : 0.925 val loss_1 : 0.412 train loss_2 : 0.15 val loss_2 : 1.45 train loss_3 : 1.83 val loss_3 : 5.58 \n",
      "................................................................................................................................................................\n",
      "Epoch 520 train loss_0 : -0.911 val loss_0 : -0.19 train loss_1 : 0.926 val loss_1 : 0.354 train loss_2 : 0.152 val loss_2 : 1.63 train loss_3 : 1.83 val loss_3 : 5.69 \n",
      "................................................................................................................................................................\n",
      "Epoch 525 train loss_0 : -0.91 val loss_0 : -0.116 train loss_1 : 0.925 val loss_1 : 0.283 train loss_2 : 0.149 val loss_2 : 1.67 train loss_3 : 1.81 val loss_3 : 5.3 \n",
      "................................................................................................................................................................\n",
      "Epoch 530 train loss_0 : -0.911 val loss_0 : -0.222 train loss_1 : 0.926 val loss_1 : 0.362 train loss_2 : 0.15 val loss_2 : 1.4 train loss_3 : 1.8 val loss_3 : 5.36 \n",
      "................................................................................................................................................................\n",
      "Epoch 535 train loss_0 : -0.911 val loss_0 : -0.31 train loss_1 : 0.926 val loss_1 : 0.432 train loss_2 : 0.149 val loss_2 : 1.22 train loss_3 : 1.81 val loss_3 : 5.35 \n",
      "................................................................................................................................................................\n",
      "Epoch 540 train loss_0 : -0.91 val loss_0 : -0.329 train loss_1 : 0.925 val loss_1 : 0.455 train loss_2 : 0.149 val loss_2 : 1.26 train loss_3 : 1.84 val loss_3 : 4.81 \n",
      "................................................................................................................................................................\n",
      "Epoch 545 train loss_0 : -0.912 val loss_0 : -0.257 train loss_1 : 0.926 val loss_1 : 0.386 train loss_2 : 0.149 val loss_2 : 1.28 train loss_3 : 1.81 val loss_3 : 5.1 \n",
      "................................................................................................................................................................\n",
      "Epoch 550 train loss_0 : -0.91 val loss_0 : -0.198 train loss_1 : 0.925 val loss_1 : 0.362 train loss_2 : 0.15 val loss_2 : 1.63 train loss_3 : 1.85 val loss_3 : 4.95 \n",
      "................................................................................................................................................................\n",
      "Epoch 555 train loss_0 : -0.91 val loss_0 : -0.205 train loss_1 : 0.925 val loss_1 : 0.36 train loss_2 : 0.148 val loss_2 : 1.55 train loss_3 : 1.81 val loss_3 : 5.29 \n",
      "................................................................................................................................................................\n",
      "Epoch 560 train loss_0 : -0.912 val loss_0 : -0.288 train loss_1 : 0.926 val loss_1 : 0.431 train loss_2 : 0.147 val loss_2 : 1.43 train loss_3 : 1.82 val loss_3 : 4.93 \n",
      "................................................................................................................................................................\n",
      "Epoch 565 train loss_0 : -0.91 val loss_0 : -0.188 train loss_1 : 0.925 val loss_1 : 0.355 train loss_2 : 0.15 val loss_2 : 1.68 train loss_3 : 1.82 val loss_3 : 5.06 \n",
      "................................................................................................................................................................\n",
      "Epoch 570 train loss_0 : -0.911 val loss_0 : -0.163 train loss_1 : 0.926 val loss_1 : 0.317 train loss_2 : 0.149 val loss_2 : 1.54 train loss_3 : 1.79 val loss_3 : 5.5 \n",
      "................................................................................................................................................................\n",
      "Epoch 575 train loss_0 : -0.911 val loss_0 : -0.243 train loss_1 : 0.926 val loss_1 : 0.394 train loss_2 : 0.15 val loss_2 : 1.5 train loss_3 : 1.78 val loss_3 : 5.93 \n",
      "................................................................................................................................................................\n",
      "Epoch 580 train loss_0 : -0.91 val loss_0 : -0.256 train loss_1 : 0.925 val loss_1 : 0.392 train loss_2 : 0.15 val loss_2 : 1.36 train loss_3 : 1.82 val loss_3 : 5.38 \n",
      "................................................................................................................................................................\n",
      "Epoch 585 train loss_0 : -0.912 val loss_0 : -0.279 train loss_1 : 0.927 val loss_1 : 0.422 train loss_2 : 0.148 val loss_2 : 1.43 train loss_3 : 1.82 val loss_3 : 4.85 \n",
      "................................................................................................................................................................\n",
      "Epoch 590 train loss_0 : -0.911 val loss_0 : -0.171 train loss_1 : 0.926 val loss_1 : 0.341 train loss_2 : 0.148 val loss_2 : 1.7 train loss_3 : 1.8 val loss_3 : 5.79 \n",
      "................................................................................................................................................................\n",
      "Epoch 595 train loss_0 : -0.913 val loss_0 : -0.215 train loss_1 : 0.928 val loss_1 : 0.374 train loss_2 : 0.148 val loss_2 : 1.59 train loss_3 : 1.81 val loss_3 : 4.8 \n",
      "................................................................................................................................................................\n",
      "Epoch 600 train loss_0 : -0.911 val loss_0 : -0.191 train loss_1 : 0.926 val loss_1 : 0.359 train loss_2 : 0.146 val loss_2 : 1.68 train loss_3 : 1.8 val loss_3 : 4.94 \n",
      "................................................................................................................................................................\n",
      "Epoch 605 train loss_0 : -0.91 val loss_0 : -0.249 train loss_1 : 0.925 val loss_1 : 0.394 train loss_2 : 0.152 val loss_2 : 1.45 train loss_3 : 1.83 val loss_3 : 5.13 \n",
      "................................................................................................................................................................\n",
      "Epoch 610 train loss_0 : -0.909 val loss_0 : -0.243 train loss_1 : 0.924 val loss_1 : 0.401 train loss_2 : 0.148 val loss_2 : 1.58 train loss_3 : 1.8 val loss_3 : 6.07 \n",
      "................................................................................................................................................................\n",
      "Epoch 615 train loss_0 : -0.912 val loss_0 : -0.129 train loss_1 : 0.926 val loss_1 : 0.315 train loss_2 : 0.147 val loss_2 : 1.87 train loss_3 : 1.78 val loss_3 : 5.39 \n",
      "................................................................................................................................................................\n",
      "Epoch 620 train loss_0 : -0.912 val loss_0 : -0.208 train loss_1 : 0.927 val loss_1 : 0.368 train loss_2 : 0.15 val loss_2 : 1.59 train loss_3 : 1.83 val loss_3 : 5.31 \n",
      "................................................................................................................................................................\n",
      "Epoch 625 train loss_0 : -0.911 val loss_0 : -0.169 train loss_1 : 0.926 val loss_1 : 0.34 train loss_2 : 0.15 val loss_2 : 1.7 train loss_3 : 1.82 val loss_3 : 5.21 \n",
      "................................................................................................................................................................\n",
      "Epoch 630 train loss_0 : -0.911 val loss_0 : -0.328 train loss_1 : 0.926 val loss_1 : 0.454 train loss_2 : 0.149 val loss_2 : 1.26 train loss_3 : 1.8 val loss_3 : 4.97 \n",
      "................................................................................................................................................................\n",
      "Epoch 635 train loss_0 : -0.911 val loss_0 : -0.245 train loss_1 : 0.926 val loss_1 : 0.384 train loss_2 : 0.15 val loss_2 : 1.39 train loss_3 : 1.81 val loss_3 : 5.13 \n",
      "................................................................................................................................................................\n",
      "Epoch 640 train loss_0 : -0.911 val loss_0 : -0.172 train loss_1 : 0.926 val loss_1 : 0.337 train loss_2 : 0.148 val loss_2 : 1.66 train loss_3 : 1.82 val loss_3 : 5.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 645 train loss_0 : -0.911 val loss_0 : -0.22 train loss_1 : 0.926 val loss_1 : 0.375 train loss_2 : 0.15 val loss_2 : 1.55 train loss_3 : 1.84 val loss_3 : 5.61 \n",
      "................................................................................................................................................................\n",
      "Epoch 650 train loss_0 : -0.91 val loss_0 : -0.268 train loss_1 : 0.925 val loss_1 : 0.41 train loss_2 : 0.147 val loss_2 : 1.42 train loss_3 : 1.79 val loss_3 : 5.15 \n",
      "................................................................................................................................................................\n",
      "Epoch 655 train loss_0 : -0.911 val loss_0 : -0.185 train loss_1 : 0.926 val loss_1 : 0.339 train loss_2 : 0.147 val loss_2 : 1.54 train loss_3 : 1.8 val loss_3 : 5.15 \n",
      "................................................................................................................................................................\n",
      "Epoch 660 train loss_0 : -0.911 val loss_0 : -0.257 train loss_1 : 0.926 val loss_1 : 0.398 train loss_2 : 0.148 val loss_2 : 1.41 train loss_3 : 1.81 val loss_3 : 5.17 \n",
      "................................................................................................................................................................\n",
      "Epoch 665 train loss_0 : -0.912 val loss_0 : -0.184 train loss_1 : 0.926 val loss_1 : 0.34 train loss_2 : 0.147 val loss_2 : 1.56 train loss_3 : 1.8 val loss_3 : 4.94 \n",
      "................................................................................................................................................................\n",
      "Epoch 670 train loss_0 : -0.914 val loss_0 : -0.166 train loss_1 : 0.928 val loss_1 : 0.332 train loss_2 : 0.145 val loss_2 : 1.66 train loss_3 : 1.77 val loss_3 : 4.87 \n",
      "................................................................................................................................................................\n",
      "Epoch 675 train loss_0 : -0.912 val loss_0 : -0.151 train loss_1 : 0.927 val loss_1 : 0.313 train loss_2 : 0.149 val loss_2 : 1.62 train loss_3 : 1.81 val loss_3 : 5.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 680 train loss_0 : -0.911 val loss_0 : -0.184 train loss_1 : 0.925 val loss_1 : 0.345 train loss_2 : 0.147 val loss_2 : 1.61 train loss_3 : 1.8 val loss_3 : 5.17 \n",
      "................................................................................................................................................................\n",
      "Epoch 685 train loss_0 : -0.912 val loss_0 : -0.254 train loss_1 : 0.927 val loss_1 : 0.404 train loss_2 : 0.148 val loss_2 : 1.5 train loss_3 : 1.79 val loss_3 : 4.77 \n",
      "................................................................................................................................................................\n",
      "Epoch 690 train loss_0 : -0.911 val loss_0 : -0.272 train loss_1 : 0.926 val loss_1 : 0.406 train loss_2 : 0.152 val loss_2 : 1.34 train loss_3 : 1.82 val loss_3 : 5.2 \n",
      "................................................................................................................................................................\n",
      "Epoch 695 train loss_0 : -0.912 val loss_0 : -0.302 train loss_1 : 0.926 val loss_1 : 0.434 train loss_2 : 0.144 val loss_2 : 1.31 train loss_3 : 1.75 val loss_3 : 5.36 \n",
      "................................................................................................................................................................\n",
      "Epoch 700 train loss_0 : -0.912 val loss_0 : -0.211 train loss_1 : 0.927 val loss_1 : 0.362 train loss_2 : 0.149 val loss_2 : 1.51 train loss_3 : 1.81 val loss_3 : 4.56 \n",
      "................................................................................................................................................................\n",
      "Epoch 705 train loss_0 : -0.912 val loss_0 : -0.167 train loss_1 : 0.926 val loss_1 : 0.33 train loss_2 : 0.149 val loss_2 : 1.63 train loss_3 : 1.79 val loss_3 : 4.56 \n",
      "................................................................................................................................................................\n",
      "Epoch 710 train loss_0 : -0.911 val loss_0 : -0.236 train loss_1 : 0.926 val loss_1 : 0.405 train loss_2 : 0.148 val loss_2 : 1.68 train loss_3 : 1.81 val loss_3 : 5.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 715 train loss_0 : -0.913 val loss_0 : -0.29 train loss_1 : 0.928 val loss_1 : 0.419 train loss_2 : 0.149 val loss_2 : 1.29 train loss_3 : 1.81 val loss_3 : 5.1 \n",
      "................................................................................................................................................................\n",
      "Epoch 720 train loss_0 : -0.91 val loss_0 : -0.23 train loss_1 : 0.925 val loss_1 : 0.385 train loss_2 : 0.15 val loss_2 : 1.55 train loss_3 : 1.82 val loss_3 : 5.29 \n",
      "................................................................................................................................................................\n",
      "Epoch 725 train loss_0 : -0.912 val loss_0 : -0.305 train loss_1 : 0.926 val loss_1 : 0.44 train loss_2 : 0.146 val loss_2 : 1.36 train loss_3 : 1.8 val loss_3 : 5.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 730 train loss_0 : -0.913 val loss_0 : -0.248 train loss_1 : 0.928 val loss_1 : 0.398 train loss_2 : 0.146 val loss_2 : 1.5 train loss_3 : 1.81 val loss_3 : 4.49 \n",
      "................................................................................................................................................................\n",
      "Epoch 735 train loss_0 : -0.913 val loss_0 : -0.205 train loss_1 : 0.928 val loss_1 : 0.355 train loss_2 : 0.148 val loss_2 : 1.5 train loss_3 : 1.79 val loss_3 : 5.01 \n",
      "................................................................................................................................................................\n",
      "Epoch 740 train loss_0 : -0.911 val loss_0 : -0.243 train loss_1 : 0.926 val loss_1 : 0.385 train loss_2 : 0.146 val loss_2 : 1.42 train loss_3 : 1.77 val loss_3 : 4.9 \n",
      "................................................................................................................................................................\n",
      "Epoch 745 train loss_0 : -0.912 val loss_0 : -0.263 train loss_1 : 0.927 val loss_1 : 0.409 train loss_2 : 0.148 val loss_2 : 1.46 train loss_3 : 1.81 val loss_3 : 5.38 \n",
      "................................................................................................................................................................\n",
      "Epoch 750 train loss_0 : -0.913 val loss_0 : -0.216 train loss_1 : 0.927 val loss_1 : 0.376 train loss_2 : 0.146 val loss_2 : 1.6 train loss_3 : 1.81 val loss_3 : 4.87 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8359... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ae4cb422c3467ca4371bc7e95c448b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.19MB of 2.19MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/loss_0</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss_1</td><td>▁▅▆▇▇▇██████████████████████████████████</td></tr><tr><td>train/loss_2</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss_3</td><td>█▆▅▄▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/corr_mean</td><td>▁▁▃█████</td></tr><tr><td>val/loss_0</td><td>▂▂▆▅▇▅▅▅▄▄▅▆▅▆▁▁▄▅▂▃▆▄▄▅▆▃▆▆▆▁▆▅▄▂█▇▇▆▅▂</td></tr><tr><td>val/loss_1</td><td>▇▇▃▃▂▄▄▃▅▅▄▄▄▃█▇▄▄▇▆▃▅▅▄▃▆▃▄▃█▃▄▅█▁▃▃▄▄▇</td></tr><tr><td>val/loss_2</td><td>▂▃▃▃▅▃▄▃▃▂▄▆▆▅▁▂▃▅▂▄▅▄▃▅▆▄▆▆▆▃▅▅▄▃▆█▇█▆▄</td></tr><tr><td>val/loss_3</td><td>█▅▅▄▅▄▄▃▃▄▂▂▃▂▂▂▂▁▃▁▃▂▂▁▁▂▂▁▂▂▁▁▂▁▁▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/loss_0</td><td>-0.91281</td></tr><tr><td>train/loss_1</td><td>0.92739</td></tr><tr><td>train/loss_2</td><td>0.14573</td></tr><tr><td>train/loss_3</td><td>1.80527</td></tr><tr><td>val/loss_0</td><td>-0.21633</td></tr><tr><td>val/loss_1</td><td>0.37592</td></tr><tr><td>val/loss_2</td><td>1.59587</td></tr><tr><td>val/loss_3</td><td>4.87173</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 16 media file(s), 0 artifact file(s) and 9 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">deft-serenity-343</strong>: <a href=\"https://wandb.ai/koval_alvi/eeg_fmri/runs/2gvge4j1\" target=\"_blank\">https://wandb.ai/koval_alvi/eeg_fmri/runs/2gvge4j1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220510_174527-2gvge4j1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels for decoder [ 32  32  32 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/koval_alvi/eeg_fmri/runs/36wy5j7d\" target=\"_blank\">laced-durian-350</a></strong> to <a href=\"https://wandb.ai/koval_alvi/eeg_fmri\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_electrodes': 30, 'n_freqs': 16, 'n_channels_out': 6, 'channels': [128, 128, 128, 64], 'kernel_sizes': [5, 5, 3], 'strides': [8, 8, 4], 'dilation': [1, 1, 1], 'decoder_reduce': 4, 'corr_proj_size': 64, 'window_cross_corr': 512, 'dataset_name': 'CWL', 'new_fps': 100, 'freqs': array([ 2.        ,  2.59420132,  3.36494024,  4.3646662 ,  5.6614114 ,\n",
      "        7.34342046,  9.52515552, 12.3550855 , 16.02578954, 20.78706217,\n",
      "       26.96291204, 34.97361097, 45.36429384, 58.84205542, 76.32406886,\n",
      "       99.        ]), 'n_channels': 30, 'n_roi': 6, 'bold_delay': 6, 'to_many': True, 'random_subsample': True, 'sample_per_epoch': 512, 'WINDOW_SIZE': 2048, 'optimizer': 'adamW', 'lr': 0.0003, 'weight_decay': 0.0003, 'batch_size': 16, 'preproc_type': 'dB_log', 'loss_function': 'mse_corr', 'model_type': 'AE_CrossCorr_improved'}\n",
      "CrossCorrAutoEncoder1D(\n",
      "  (project): Sequential(\n",
      "    (0): Conv1d(6960, 64, kernel_size=(1,), stride=(1,))\n",
      "    (1): Dropout(p=0.25, inplace=False)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (spatial_reduce): ConvBlock(\n",
      "    (conv1d): Conv1d(480, 128, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (activation): GELU()\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (encoder): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (conv1d): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELU()\n",
      "      (drop): Dropout(p=0.3, inplace=False)\n",
      "      (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1d): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELU()\n",
      "      (drop): Dropout(p=0.3, inplace=False)\n",
      "      (downsample): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv1d): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (activation): GELU()\n",
      "      (drop): Dropout(p=0.3, inplace=False)\n",
      "      (downsample): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (mapping): ConvBlock(\n",
      "    (conv1d): Conv1d(128, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (activation): GELU()\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): UpConvBlock(\n",
      "      (conv_block): ConvBlock(\n",
      "        (conv1d): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (upsample): Upsample(scale_factor=4.0, mode=linear)\n",
      "    )\n",
      "    (1): UpConvBlock(\n",
      "      (conv_block): ConvBlock(\n",
      "        (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "    )\n",
      "    (2): UpConvBlock(\n",
      "      (conv_block): ConvBlock(\n",
      "        (conv1d): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
      "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "        (activation): GELU()\n",
      "        (drop): Dropout(p=0.3, inplace=False)\n",
      "        (downsample): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (upsample): Upsample(scale_factor=8.0, mode=linear)\n",
      "    )\n",
      "  )\n",
      "  (conv1x1_one): Conv1d(32, 6, kernel_size=(1,), stride=(1,), padding=same)\n",
      ")\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv1d-1        [4, 6960, 4]         445,504         445,504\n",
      "         Dropout-2          [4, 64, 4]               0               0\n",
      "            ReLU-3          [4, 64, 4]               0               0\n",
      "       ConvBlock-4      [4, 480, 2048]         184,576         184,576\n",
      "       ConvBlock-5      [4, 128, 2048]          82,176          82,176\n",
      "       ConvBlock-6       [4, 128, 256]          82,176          82,176\n",
      "       ConvBlock-7        [4, 128, 32]          24,704          24,704\n",
      "       ConvBlock-8         [4, 128, 8]          16,640          16,640\n",
      "     UpConvBlock-9         [4, 128, 8]          12,352          12,352\n",
      "    UpConvBlock-10         [4, 32, 32]           5,184           5,184\n",
      "    UpConvBlock-11        [4, 32, 256]           5,184           5,184\n",
      "         Conv1d-12       [4, 32, 2048]             198             198\n",
      "=======================================================================\n",
      "Total params: 858,694\n",
      "Trainable params: 858,694\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "Starting Training of our model \n",
      "Number of samples 512 \n",
      "Size of batch: 16 Number batches 32\n",
      "................................................................................................................................................................\n",
      "Epoch 5 train loss_0 : -0.559 val loss_0 : -0.233 train loss_1 : 0.62 val loss_1 : 0.364 train loss_2 : 0.613 val loss_2 : 1.31 train loss_3 : 4.74 val loss_3 : 9.58 \n",
      "................................................................................................................................................................\n",
      "Epoch 10 train loss_0 : -0.695 val loss_0 : -0.285 train loss_1 : 0.742 val loss_1 : 0.411 train loss_2 : 0.472 val loss_2 : 1.26 train loss_3 : 4.68 val loss_3 : 9.62 \n",
      "................................................................................................................................................................\n",
      "Epoch 15 train loss_0 : -0.756 val loss_0 : -0.2 train loss_1 : 0.796 val loss_1 : 0.351 train loss_2 : 0.395 val loss_2 : 1.5 train loss_3 : 4.59 val loss_3 : 8.71 \n",
      "................................................................................................................................................................\n",
      "Epoch 20 train loss_0 : -0.784 val loss_0 : -0.28 train loss_1 : 0.819 val loss_1 : 0.412 train loss_2 : 0.351 val loss_2 : 1.32 train loss_3 : 4.28 val loss_3 : 8.27 \n",
      "................................................................................................................................................................\n",
      "Epoch 25 train loss_0 : -0.804 val loss_0 : -0.227 train loss_1 : 0.836 val loss_1 : 0.367 train loss_2 : 0.319 val loss_2 : 1.4 train loss_3 : 3.95 val loss_3 : 8.17 \n",
      "................................................................................................................................................................\n",
      "Epoch 30 train loss_0 : -0.82 val loss_0 : -0.208 train loss_1 : 0.85 val loss_1 : 0.359 train loss_2 : 0.294 val loss_2 : 1.51 train loss_3 : 3.71 val loss_3 : 7.68 \n",
      "................................................................................................................................................................\n",
      "Epoch 35 train loss_0 : -0.829 val loss_0 : -0.225 train loss_1 : 0.857 val loss_1 : 0.369 train loss_2 : 0.285 val loss_2 : 1.44 train loss_3 : 3.61 val loss_3 : 7.15 \n",
      "................................................................................................................................................................\n",
      "Epoch 40 train loss_0 : -0.84 val loss_0 : -0.282 train loss_1 : 0.866 val loss_1 : 0.418 train loss_2 : 0.261 val loss_2 : 1.36 train loss_3 : 3.41 val loss_3 : 7.32 \n",
      "................................................................................................................................................................\n",
      "Epoch 45 train loss_0 : -0.845 val loss_0 : -0.215 train loss_1 : 0.871 val loss_1 : 0.365 train loss_2 : 0.253 val loss_2 : 1.5 train loss_3 : 3.32 val loss_3 : 6.95 \n",
      "................................................................................................................................................................\n",
      "Epoch 50 train loss_0 : -0.851 val loss_0 : -0.261 train loss_1 : 0.876 val loss_1 : 0.401 train loss_2 : 0.25 val loss_2 : 1.4 train loss_3 : 3.2 val loss_3 : 7.4 \n",
      "................................................................................................................................................................\n",
      "Epoch 55 train loss_0 : -0.856 val loss_0 : -0.274 train loss_1 : 0.88 val loss_1 : 0.412 train loss_2 : 0.239 val loss_2 : 1.38 train loss_3 : 3.1 val loss_3 : 7.02 \n",
      "................................................................................................................................................................\n",
      "Epoch 60 train loss_0 : -0.86 val loss_0 : -0.325 train loss_1 : 0.883 val loss_1 : 0.453 train loss_2 : 0.229 val loss_2 : 1.28 train loss_3 : 2.97 val loss_3 : 6.9 \n",
      "................................................................................................................................................................\n",
      "Epoch 65 train loss_0 : -0.864 val loss_0 : -0.236 train loss_1 : 0.886 val loss_1 : 0.383 train loss_2 : 0.224 val loss_2 : 1.47 train loss_3 : 2.86 val loss_3 : 6.29 \n",
      "................................................................................................................................................................\n",
      "Epoch 70 train loss_0 : -0.868 val loss_0 : -0.236 train loss_1 : 0.89 val loss_1 : 0.386 train loss_2 : 0.222 val loss_2 : 1.5 train loss_3 : 2.75 val loss_3 : 6.3 \n",
      "................................................................................................................................................................\n",
      "Epoch 75 train loss_0 : -0.874 val loss_0 : -0.287 train loss_1 : 0.895 val loss_1 : 0.42 train loss_2 : 0.212 val loss_2 : 1.33 train loss_3 : 2.66 val loss_3 : 6.71 \n",
      "................................................................................................................................................................\n",
      "Epoch 80 train loss_0 : -0.876 val loss_0 : -0.257 train loss_1 : 0.897 val loss_1 : 0.396 train loss_2 : 0.207 val loss_2 : 1.39 train loss_3 : 2.62 val loss_3 : 6.69 \n",
      "................................................................................................................................................................\n",
      "Epoch 85 train loss_0 : -0.879 val loss_0 : -0.334 train loss_1 : 0.899 val loss_1 : 0.454 train loss_2 : 0.202 val loss_2 : 1.2 train loss_3 : 2.55 val loss_3 : 6.6 \n",
      "................................................................................................................................................................\n",
      "Epoch 90 train loss_0 : -0.88 val loss_0 : -0.228 train loss_1 : 0.9 val loss_1 : 0.379 train loss_2 : 0.198 val loss_2 : 1.51 train loss_3 : 2.46 val loss_3 : 6.29 \n",
      "................................................................................................................................................................\n",
      "Epoch 95 train loss_0 : -0.881 val loss_0 : -0.292 train loss_1 : 0.901 val loss_1 : 0.422 train loss_2 : 0.194 val loss_2 : 1.3 train loss_3 : 2.48 val loss_3 : 6.33 \n",
      "................................................................................................................................................................\n",
      "Epoch 100 train loss_0 : -0.883 val loss_0 : -0.276 train loss_1 : 0.903 val loss_1 : 0.411 train loss_2 : 0.197 val loss_2 : 1.35 train loss_3 : 2.41 val loss_3 : 5.89 \n",
      "................................................................................................................................................................\n",
      "Epoch 105 train loss_0 : -0.887 val loss_0 : -0.287 train loss_1 : 0.906 val loss_1 : 0.418 train loss_2 : 0.189 val loss_2 : 1.32 train loss_3 : 2.36 val loss_3 : 6.13 \n",
      "................................................................................................................................................................\n",
      "Epoch 110 train loss_0 : -0.887 val loss_0 : -0.245 train loss_1 : 0.906 val loss_1 : 0.397 train loss_2 : 0.19 val loss_2 : 1.52 train loss_3 : 2.31 val loss_3 : 5.85 \n",
      "................................................................................................................................................................\n",
      "Epoch 115 train loss_0 : -0.888 val loss_0 : -0.291 train loss_1 : 0.906 val loss_1 : 0.428 train loss_2 : 0.186 val loss_2 : 1.36 train loss_3 : 2.27 val loss_3 : 5.93 \n",
      "................................................................................................................................................................\n",
      "Epoch 120 train loss_0 : -0.892 val loss_0 : -0.243 train loss_1 : 0.91 val loss_1 : 0.386 train loss_2 : 0.186 val loss_2 : 1.43 train loss_3 : 2.26 val loss_3 : 6.51 \n",
      "................................................................................................................................................................\n",
      "Epoch 125 train loss_0 : -0.892 val loss_0 : -0.267 train loss_1 : 0.91 val loss_1 : 0.402 train loss_2 : 0.184 val loss_2 : 1.35 train loss_3 : 2.25 val loss_3 : 5.8 \n",
      "................................................................................................................................................................\n",
      "Epoch 130 train loss_0 : -0.893 val loss_0 : -0.273 train loss_1 : 0.911 val loss_1 : 0.415 train loss_2 : 0.179 val loss_2 : 1.42 train loss_3 : 2.25 val loss_3 : 6.14 \n",
      "................................................................................................................................................................\n",
      "Epoch 135 train loss_0 : -0.892 val loss_0 : -0.247 train loss_1 : 0.91 val loss_1 : 0.392 train loss_2 : 0.178 val loss_2 : 1.45 train loss_3 : 2.2 val loss_3 : 6.66 \n",
      "................................................................................................................................................................\n",
      "Epoch 140 train loss_0 : -0.895 val loss_0 : -0.283 train loss_1 : 0.913 val loss_1 : 0.419 train loss_2 : 0.179 val loss_2 : 1.36 train loss_3 : 2.18 val loss_3 : 5.98 \n",
      "................................................................................................................................................................\n",
      "Epoch 145 train loss_0 : -0.897 val loss_0 : -0.29 train loss_1 : 0.914 val loss_1 : 0.426 train loss_2 : 0.174 val loss_2 : 1.37 train loss_3 : 2.14 val loss_3 : 5.69 \n",
      "................................................................................................................................................................\n",
      "Epoch 150 train loss_0 : -0.895 val loss_0 : -0.271 train loss_1 : 0.912 val loss_1 : 0.407 train loss_2 : 0.176 val loss_2 : 1.35 train loss_3 : 2.14 val loss_3 : 5.54 \n",
      "................................................................................................................................................................\n",
      "Epoch 155 train loss_0 : -0.895 val loss_0 : -0.313 train loss_1 : 0.913 val loss_1 : 0.448 train loss_2 : 0.174 val loss_2 : 1.36 train loss_3 : 2.13 val loss_3 : 6.2 \n",
      "................................................................................................................................................................\n",
      "Epoch 160 train loss_0 : -0.897 val loss_0 : -0.245 train loss_1 : 0.914 val loss_1 : 0.402 train loss_2 : 0.174 val loss_2 : 1.57 train loss_3 : 2.12 val loss_3 : 5.54 \n",
      "................................................................................................................................................................\n",
      "Epoch 165 train loss_0 : -0.896 val loss_0 : -0.365 train loss_1 : 0.914 val loss_1 : 0.487 train loss_2 : 0.171 val loss_2 : 1.22 train loss_3 : 2.13 val loss_3 : 6.04 \n",
      "................................................................................................................................................................\n",
      "Epoch 170 train loss_0 : -0.899 val loss_0 : -0.253 train loss_1 : 0.916 val loss_1 : 0.398 train loss_2 : 0.168 val loss_2 : 1.45 train loss_3 : 2.07 val loss_3 : 6.08 \n",
      "................................................................................................................................................................\n",
      "Epoch 175 train loss_0 : -0.898 val loss_0 : -0.209 train loss_1 : 0.916 val loss_1 : 0.365 train loss_2 : 0.174 val loss_2 : 1.56 train loss_3 : 2.1 val loss_3 : 5.81 \n",
      "................................................................................................................................................................\n",
      "Epoch 180 train loss_0 : -0.898 val loss_0 : -0.342 train loss_1 : 0.915 val loss_1 : 0.467 train loss_2 : 0.172 val loss_2 : 1.25 train loss_3 : 2.08 val loss_3 : 6.17 \n",
      "................................................................................................................................................................\n",
      "Epoch 185 train loss_0 : -0.899 val loss_0 : -0.223 train loss_1 : 0.916 val loss_1 : 0.373 train loss_2 : 0.173 val loss_2 : 1.5 train loss_3 : 2.06 val loss_3 : 5.77 \n",
      "................................................................................................................................................................\n",
      "Epoch 190 train loss_0 : -0.9 val loss_0 : -0.248 train loss_1 : 0.917 val loss_1 : 0.398 train loss_2 : 0.167 val loss_2 : 1.49 train loss_3 : 2.02 val loss_3 : 6.16 \n",
      "................................................................................................................................................................\n",
      "Epoch 195 train loss_0 : -0.901 val loss_0 : -0.279 train loss_1 : 0.917 val loss_1 : 0.418 train loss_2 : 0.167 val loss_2 : 1.39 train loss_3 : 2.03 val loss_3 : 5.74 \n",
      "................................................................................................................................................................\n",
      "Epoch 200 train loss_0 : -0.901 val loss_0 : -0.267 train loss_1 : 0.918 val loss_1 : 0.409 train loss_2 : 0.165 val loss_2 : 1.42 train loss_3 : 1.99 val loss_3 : 6.33 \n",
      "................................................................................................................................................................\n",
      "Epoch 205 train loss_0 : -0.902 val loss_0 : -0.215 train loss_1 : 0.918 val loss_1 : 0.369 train loss_2 : 0.167 val loss_2 : 1.54 train loss_3 : 2.03 val loss_3 : 6.13 \n",
      "................................................................................................................................................................\n",
      "Epoch 210 train loss_0 : -0.901 val loss_0 : -0.178 train loss_1 : 0.917 val loss_1 : 0.339 train loss_2 : 0.163 val loss_2 : 1.62 train loss_3 : 1.98 val loss_3 : 6.44 \n",
      "................................................................................................................................................................\n",
      "Epoch 215 train loss_0 : -0.903 val loss_0 : -0.225 train loss_1 : 0.919 val loss_1 : 0.387 train loss_2 : 0.165 val loss_2 : 1.62 train loss_3 : 2.01 val loss_3 : 6.01 \n",
      "................................................................................................................................................................\n",
      "Epoch 220 train loss_0 : -0.902 val loss_0 : -0.327 train loss_1 : 0.919 val loss_1 : 0.456 train loss_2 : 0.164 val loss_2 : 1.29 train loss_3 : 1.98 val loss_3 : 5.87 \n",
      "................................................................................................................................................................\n",
      "Epoch 225 train loss_0 : -0.902 val loss_0 : -0.298 train loss_1 : 0.919 val loss_1 : 0.441 train loss_2 : 0.165 val loss_2 : 1.43 train loss_3 : 2.02 val loss_3 : 5.75 \n",
      "................................................................................................................................................................\n",
      "Epoch 230 train loss_0 : -0.904 val loss_0 : -0.305 train loss_1 : 0.92 val loss_1 : 0.447 train loss_2 : 0.16 val loss_2 : 1.42 train loss_3 : 1.94 val loss_3 : 5.66 \n",
      "................................................................................................................................................................\n",
      "Epoch 235 train loss_0 : -0.904 val loss_0 : -0.367 train loss_1 : 0.92 val loss_1 : 0.489 train loss_2 : 0.16 val loss_2 : 1.23 train loss_3 : 1.94 val loss_3 : 5.64 \n",
      "................................................................................................................................................................\n",
      "Epoch 240 train loss_0 : -0.904 val loss_0 : -0.233 train loss_1 : 0.921 val loss_1 : 0.388 train loss_2 : 0.163 val loss_2 : 1.56 train loss_3 : 1.95 val loss_3 : 5.77 \n",
      "................................................................................................................................................................\n",
      "Epoch 245 train loss_0 : -0.904 val loss_0 : -0.24 train loss_1 : 0.92 val loss_1 : 0.387 train loss_2 : 0.161 val loss_2 : 1.48 train loss_3 : 1.96 val loss_3 : 6.12 \n",
      "................................................................................................................................................................\n",
      "Epoch 250 train loss_0 : -0.905 val loss_0 : -0.33 train loss_1 : 0.921 val loss_1 : 0.472 train loss_2 : 0.156 val loss_2 : 1.42 train loss_3 : 1.95 val loss_3 : 5.38 \n",
      "................................................................................................................................................................\n",
      "Epoch 255 train loss_0 : -0.904 val loss_0 : -0.234 train loss_1 : 0.92 val loss_1 : 0.383 train loss_2 : 0.16 val loss_2 : 1.49 train loss_3 : 1.94 val loss_3 : 5.59 \n",
      "................................................................................................................................................................\n",
      "Epoch 260 train loss_0 : -0.904 val loss_0 : -0.228 train loss_1 : 0.92 val loss_1 : 0.384 train loss_2 : 0.159 val loss_2 : 1.55 train loss_3 : 1.94 val loss_3 : 5.57 \n",
      "................................................................................................................................................................\n",
      "Epoch 265 train loss_0 : -0.906 val loss_0 : -0.399 train loss_1 : 0.921 val loss_1 : 0.514 train loss_2 : 0.157 val loss_2 : 1.15 train loss_3 : 1.94 val loss_3 : 5.75 \n",
      "................................................................................................................................................................\n",
      "Epoch 270 train loss_0 : -0.904 val loss_0 : -0.261 train loss_1 : 0.92 val loss_1 : 0.411 train loss_2 : 0.161 val loss_2 : 1.5 train loss_3 : 1.91 val loss_3 : 5.98 \n",
      "................................................................................................................................................................\n",
      "Epoch 275 train loss_0 : -0.904 val loss_0 : -0.307 train loss_1 : 0.919 val loss_1 : 0.446 train loss_2 : 0.16 val loss_2 : 1.4 train loss_3 : 1.92 val loss_3 : 5.99 \n",
      "................................................................................................................................................................\n",
      "Epoch 280 train loss_0 : -0.904 val loss_0 : -0.387 train loss_1 : 0.919 val loss_1 : 0.509 train loss_2 : 0.156 val loss_2 : 1.22 train loss_3 : 1.93 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 285 train loss_0 : -0.906 val loss_0 : -0.27 train loss_1 : 0.921 val loss_1 : 0.419 train loss_2 : 0.156 val loss_2 : 1.49 train loss_3 : 1.88 val loss_3 : 5.3 \n",
      "................................................................................................................................................................\n",
      "Epoch 290 train loss_0 : -0.906 val loss_0 : -0.31 train loss_1 : 0.922 val loss_1 : 0.447 train loss_2 : 0.161 val loss_2 : 1.37 train loss_3 : 1.92 val loss_3 : 5.61 \n",
      "................................................................................................................................................................\n",
      "Epoch 295 train loss_0 : -0.906 val loss_0 : -0.293 train loss_1 : 0.922 val loss_1 : 0.432 train loss_2 : 0.156 val loss_2 : 1.4 train loss_3 : 1.88 val loss_3 : 5.33 \n",
      "................................................................................................................................................................\n",
      "Epoch 300 train loss_0 : -0.907 val loss_0 : -0.373 train loss_1 : 0.923 val loss_1 : 0.501 train loss_2 : 0.156 val loss_2 : 1.28 train loss_3 : 1.86 val loss_3 : 5.66 \n",
      "................................................................................................................................................................\n",
      "Epoch 305 train loss_0 : -0.907 val loss_0 : -0.348 train loss_1 : 0.923 val loss_1 : 0.481 train loss_2 : 0.156 val loss_2 : 1.33 train loss_3 : 1.91 val loss_3 : 5.68 \n",
      "................................................................................................................................................................\n",
      "Epoch 310 train loss_0 : -0.905 val loss_0 : -0.338 train loss_1 : 0.921 val loss_1 : 0.475 train loss_2 : 0.158 val loss_2 : 1.37 train loss_3 : 1.88 val loss_3 : 5.23 \n",
      "................................................................................................................................................................\n",
      "Epoch 315 train loss_0 : -0.908 val loss_0 : -0.339 train loss_1 : 0.923 val loss_1 : 0.471 train loss_2 : 0.153 val loss_2 : 1.32 train loss_3 : 1.87 val loss_3 : 5.42 \n",
      "................................................................................................................................................................\n",
      "Epoch 320 train loss_0 : -0.906 val loss_0 : -0.375 train loss_1 : 0.922 val loss_1 : 0.499 train loss_2 : 0.154 val loss_2 : 1.25 train loss_3 : 1.87 val loss_3 : 5.2 \n",
      "................................................................................................................................................................\n",
      "Epoch 325 train loss_0 : -0.907 val loss_0 : -0.32 train loss_1 : 0.923 val loss_1 : 0.457 train loss_2 : 0.154 val loss_2 : 1.37 train loss_3 : 1.88 val loss_3 : 5.28 \n",
      "................................................................................................................................................................\n",
      "Epoch 330 train loss_0 : -0.907 val loss_0 : -0.253 train loss_1 : 0.923 val loss_1 : 0.409 train loss_2 : 0.156 val loss_2 : 1.56 train loss_3 : 1.88 val loss_3 : 5.56 \n",
      "................................................................................................................................................................\n",
      "Epoch 335 train loss_0 : -0.907 val loss_0 : -0.383 train loss_1 : 0.922 val loss_1 : 0.504 train loss_2 : 0.156 val loss_2 : 1.21 train loss_3 : 1.84 val loss_3 : 5.16 \n",
      "................................................................................................................................................................\n",
      "Epoch 340 train loss_0 : -0.906 val loss_0 : -0.378 train loss_1 : 0.921 val loss_1 : 0.502 train loss_2 : 0.156 val loss_2 : 1.24 train loss_3 : 1.88 val loss_3 : 5.13 \n",
      "................................................................................................................................................................\n",
      "Epoch 345 train loss_0 : -0.907 val loss_0 : -0.41 train loss_1 : 0.923 val loss_1 : 0.524 train loss_2 : 0.158 val loss_2 : 1.15 train loss_3 : 1.88 val loss_3 : 5.22 \n",
      "................................................................................................................................................................\n",
      "Epoch 350 train loss_0 : -0.908 val loss_0 : -0.305 train loss_1 : 0.923 val loss_1 : 0.443 train loss_2 : 0.151 val loss_2 : 1.38 train loss_3 : 1.85 val loss_3 : 5.67 \n",
      "................................................................................................................................................................\n",
      "Epoch 355 train loss_0 : -0.907 val loss_0 : -0.296 train loss_1 : 0.922 val loss_1 : 0.434 train loss_2 : 0.154 val loss_2 : 1.38 train loss_3 : 1.88 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 360 train loss_0 : -0.906 val loss_0 : -0.411 train loss_1 : 0.922 val loss_1 : 0.528 train loss_2 : 0.159 val loss_2 : 1.17 train loss_3 : 1.87 val loss_3 : 5.11 \n",
      "................................................................................................................................................................\n",
      "Epoch 365 train loss_0 : -0.908 val loss_0 : -0.314 train loss_1 : 0.923 val loss_1 : 0.447 train loss_2 : 0.153 val loss_2 : 1.33 train loss_3 : 1.86 val loss_3 : 6.08 \n",
      "................................................................................................................................................................\n",
      "Epoch 370 train loss_0 : -0.909 val loss_0 : -0.379 train loss_1 : 0.924 val loss_1 : 0.501 train loss_2 : 0.152 val loss_2 : 1.23 train loss_3 : 1.85 val loss_3 : 5.6 \n",
      "................................................................................................................................................................\n",
      "Epoch 375 train loss_0 : -0.908 val loss_0 : -0.358 train loss_1 : 0.923 val loss_1 : 0.49 train loss_2 : 0.154 val loss_2 : 1.32 train loss_3 : 1.85 val loss_3 : 4.98 \n",
      "................................................................................................................................................................\n",
      "Epoch 380 train loss_0 : -0.907 val loss_0 : -0.284 train loss_1 : 0.923 val loss_1 : 0.432 train loss_2 : 0.155 val loss_2 : 1.48 train loss_3 : 1.85 val loss_3 : 5.32 \n",
      "................................................................................................................................................................\n",
      "Epoch 385 train loss_0 : -0.91 val loss_0 : -0.388 train loss_1 : 0.925 val loss_1 : 0.51 train loss_2 : 0.155 val loss_2 : 1.22 train loss_3 : 1.86 val loss_3 : 5.29 \n",
      "................................................................................................................................................................\n",
      "Epoch 390 train loss_0 : -0.908 val loss_0 : -0.386 train loss_1 : 0.924 val loss_1 : 0.509 train loss_2 : 0.155 val loss_2 : 1.23 train loss_3 : 1.86 val loss_3 : 5.01 \n",
      "................................................................................................................................................................\n",
      "Epoch 395 train loss_0 : -0.909 val loss_0 : -0.273 train loss_1 : 0.924 val loss_1 : 0.414 train loss_2 : 0.152 val loss_2 : 1.41 train loss_3 : 1.82 val loss_3 : 5.94 \n",
      "................................................................................................................................................................\n",
      "Epoch 400 train loss_0 : -0.909 val loss_0 : -0.363 train loss_1 : 0.924 val loss_1 : 0.492 train loss_2 : 0.155 val loss_2 : 1.3 train loss_3 : 1.84 val loss_3 : 5.23 \n",
      "................................................................................................................................................................\n",
      "Epoch 405 train loss_0 : -0.908 val loss_0 : -0.378 train loss_1 : 0.923 val loss_1 : 0.503 train loss_2 : 0.153 val loss_2 : 1.25 train loss_3 : 1.81 val loss_3 : 5.42 \n",
      "................................................................................................................................................................\n",
      "Epoch 410 train loss_0 : -0.908 val loss_0 : -0.337 train loss_1 : 0.923 val loss_1 : 0.475 train loss_2 : 0.155 val loss_2 : 1.38 train loss_3 : 1.82 val loss_3 : 4.93 \n",
      "................................................................................................................................................................\n",
      "Epoch 415 train loss_0 : -0.909 val loss_0 : -0.399 train loss_1 : 0.924 val loss_1 : 0.518 train loss_2 : 0.151 val loss_2 : 1.19 train loss_3 : 1.83 val loss_3 : 5.5 \n",
      "................................................................................................................................................................\n",
      "Epoch 420 train loss_0 : -0.907 val loss_0 : -0.337 train loss_1 : 0.922 val loss_1 : 0.47 train loss_2 : 0.15 val loss_2 : 1.33 train loss_3 : 1.85 val loss_3 : 4.86 \n",
      "................................................................................................................................................................\n",
      "Epoch 425 train loss_0 : -0.908 val loss_0 : -0.356 train loss_1 : 0.923 val loss_1 : 0.482 train loss_2 : 0.152 val loss_2 : 1.26 train loss_3 : 1.8 val loss_3 : 5.26 \n",
      "................................................................................................................................................................\n",
      "Epoch 430 train loss_0 : -0.909 val loss_0 : -0.343 train loss_1 : 0.924 val loss_1 : 0.47 train loss_2 : 0.152 val loss_2 : 1.27 train loss_3 : 1.83 val loss_3 : 5.81 \n",
      "................................................................................................................................................................\n",
      "Epoch 435 train loss_0 : -0.911 val loss_0 : -0.348 train loss_1 : 0.926 val loss_1 : 0.478 train loss_2 : 0.151 val loss_2 : 1.3 train loss_3 : 1.83 val loss_3 : 5.32 \n",
      "................................................................................................................................................................\n",
      "Epoch 440 train loss_0 : -0.909 val loss_0 : -0.343 train loss_1 : 0.924 val loss_1 : 0.475 train loss_2 : 0.155 val loss_2 : 1.32 train loss_3 : 1.82 val loss_3 : 6.05 \n",
      "................................................................................................................................................................\n",
      "Epoch 445 train loss_0 : -0.91 val loss_0 : -0.357 train loss_1 : 0.925 val loss_1 : 0.486 train loss_2 : 0.148 val loss_2 : 1.3 train loss_3 : 1.83 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 450 train loss_0 : -0.908 val loss_0 : -0.387 train loss_1 : 0.923 val loss_1 : 0.514 train loss_2 : 0.15 val loss_2 : 1.28 train loss_3 : 1.83 val loss_3 : 4.82 \n",
      "................................................................................................................................................................\n",
      "Epoch 455 train loss_0 : -0.909 val loss_0 : -0.32 train loss_1 : 0.924 val loss_1 : 0.454 train loss_2 : 0.152 val loss_2 : 1.33 train loss_3 : 1.81 val loss_3 : 5.64 \n",
      "................................................................................................................................................................\n",
      "Epoch 460 train loss_0 : -0.909 val loss_0 : -0.303 train loss_1 : 0.924 val loss_1 : 0.442 train loss_2 : 0.15 val loss_2 : 1.39 train loss_3 : 1.84 val loss_3 : 5.31 \n",
      "................................................................................................................................................................\n",
      "Epoch 465 train loss_0 : -0.91 val loss_0 : -0.354 train loss_1 : 0.925 val loss_1 : 0.487 train loss_2 : 0.151 val loss_2 : 1.33 train loss_3 : 1.81 val loss_3 : 5.21 \n",
      "................................................................................................................................................................\n",
      "Epoch 470 train loss_0 : -0.908 val loss_0 : -0.299 train loss_1 : 0.923 val loss_1 : 0.439 train loss_2 : 0.15 val loss_2 : 1.4 train loss_3 : 1.81 val loss_3 : 5.53 \n",
      "................................................................................................................................................................\n",
      "Epoch 475 train loss_0 : -0.909 val loss_0 : -0.258 train loss_1 : 0.924 val loss_1 : 0.406 train loss_2 : 0.153 val loss_2 : 1.48 train loss_3 : 1.84 val loss_3 : 5.6 \n",
      "................................................................................................................................................................\n",
      "Epoch 480 train loss_0 : -0.91 val loss_0 : -0.355 train loss_1 : 0.925 val loss_1 : 0.474 train loss_2 : 0.151 val loss_2 : 1.19 train loss_3 : 1.85 val loss_3 : 5.24 \n",
      "................................................................................................................................................................\n",
      "Epoch 485 train loss_0 : -0.909 val loss_0 : -0.274 train loss_1 : 0.925 val loss_1 : 0.42 train loss_2 : 0.154 val loss_2 : 1.47 train loss_3 : 1.84 val loss_3 : 5.76 \n",
      "................................................................................................................................................................\n",
      "Epoch 490 train loss_0 : -0.911 val loss_0 : -0.285 train loss_1 : 0.926 val loss_1 : 0.424 train loss_2 : 0.149 val loss_2 : 1.39 train loss_3 : 1.8 val loss_3 : 5.22 \n",
      "................................................................................................................................................................\n",
      "Epoch 495 train loss_0 : -0.908 val loss_0 : -0.252 train loss_1 : 0.924 val loss_1 : 0.404 train loss_2 : 0.154 val loss_2 : 1.53 train loss_3 : 1.81 val loss_3 : 5.77 \n",
      "................................................................................................................................................................\n",
      "Epoch 500 train loss_0 : -0.91 val loss_0 : -0.299 train loss_1 : 0.925 val loss_1 : 0.432 train loss_2 : 0.151 val loss_2 : 1.33 train loss_3 : 1.84 val loss_3 : 5.62 \n",
      "................................................................................................................................................................\n",
      "Epoch 505 train loss_0 : -0.911 val loss_0 : -0.369 train loss_1 : 0.926 val loss_1 : 0.493 train loss_2 : 0.152 val loss_2 : 1.24 train loss_3 : 1.83 val loss_3 : 5.02 \n",
      "................................................................................................................................................................\n",
      "Epoch 510 train loss_0 : -0.909 val loss_0 : -0.261 train loss_1 : 0.924 val loss_1 : 0.409 train loss_2 : 0.152 val loss_2 : 1.47 train loss_3 : 1.82 val loss_3 : 5.97 \n",
      "................................................................................................................................................................\n",
      "Epoch 515 train loss_0 : -0.91 val loss_0 : -0.32 train loss_1 : 0.925 val loss_1 : 0.453 train loss_2 : 0.152 val loss_2 : 1.33 train loss_3 : 1.81 val loss_3 : 5.35 \n",
      "................................................................................................................................................................\n",
      "Epoch 520 train loss_0 : -0.91 val loss_0 : -0.348 train loss_1 : 0.925 val loss_1 : 0.479 train loss_2 : 0.148 val loss_2 : 1.31 train loss_3 : 1.8 val loss_3 : 5.12 \n",
      "................................................................................................................................................................\n",
      "Epoch 525 train loss_0 : -0.91 val loss_0 : -0.303 train loss_1 : 0.925 val loss_1 : 0.44 train loss_2 : 0.151 val loss_2 : 1.37 train loss_3 : 1.83 val loss_3 : 5.79 \n",
      "................................................................................................................................................................\n",
      "Epoch 530 train loss_0 : -0.91 val loss_0 : -0.376 train loss_1 : 0.926 val loss_1 : 0.504 train loss_2 : 0.152 val loss_2 : 1.28 train loss_3 : 1.81 val loss_3 : 5.1 \n",
      "................................................................................................................................................................\n",
      "Epoch 535 train loss_0 : -0.91 val loss_0 : -0.314 train loss_1 : 0.926 val loss_1 : 0.444 train loss_2 : 0.152 val loss_2 : 1.3 train loss_3 : 1.82 val loss_3 : 5.33 \n",
      "................................................................................................................................................................\n",
      "Epoch 540 train loss_0 : -0.911 val loss_0 : -0.249 train loss_1 : 0.926 val loss_1 : 0.397 train loss_2 : 0.15 val loss_2 : 1.47 train loss_3 : 1.83 val loss_3 : 5.41 \n",
      "................................................................................................................................................................\n",
      "Epoch 545 train loss_0 : -0.909 val loss_0 : -0.317 train loss_1 : 0.924 val loss_1 : 0.454 train loss_2 : 0.148 val loss_2 : 1.37 train loss_3 : 1.81 val loss_3 : 5.12 \n",
      "................................................................................................................................................................\n",
      "Epoch 550 train loss_0 : -0.911 val loss_0 : -0.335 train loss_1 : 0.926 val loss_1 : 0.466 train loss_2 : 0.15 val loss_2 : 1.32 train loss_3 : 1.82 val loss_3 : 6.16 \n",
      "................................................................................................................................................................\n",
      "Epoch 555 train loss_0 : -0.91 val loss_0 : -0.287 train loss_1 : 0.925 val loss_1 : 0.434 train loss_2 : 0.15 val loss_2 : 1.47 train loss_3 : 1.82 val loss_3 : 5.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 560 train loss_0 : -0.91 val loss_0 : -0.262 train loss_1 : 0.925 val loss_1 : 0.413 train loss_2 : 0.148 val loss_2 : 1.51 train loss_3 : 1.8 val loss_3 : 5.2 \n",
      "................................................................................................................................................................\n",
      "Epoch 565 train loss_0 : -0.909 val loss_0 : -0.368 train loss_1 : 0.924 val loss_1 : 0.493 train loss_2 : 0.147 val loss_2 : 1.26 train loss_3 : 1.79 val loss_3 : 4.9 \n",
      "................................................................................................................................................................\n",
      "Epoch 570 train loss_0 : -0.91 val loss_0 : -0.312 train loss_1 : 0.925 val loss_1 : 0.444 train loss_2 : 0.147 val loss_2 : 1.31 train loss_3 : 1.77 val loss_3 : 5.64 \n",
      "................................................................................................................................................................\n",
      "Epoch 575 train loss_0 : -0.911 val loss_0 : -0.327 train loss_1 : 0.926 val loss_1 : 0.455 train loss_2 : 0.149 val loss_2 : 1.28 train loss_3 : 1.8 val loss_3 : 5.21 \n",
      "................................................................................................................................................................\n",
      "Epoch 580 train loss_0 : -0.91 val loss_0 : -0.297 train loss_1 : 0.925 val loss_1 : 0.431 train loss_2 : 0.15 val loss_2 : 1.34 train loss_3 : 1.8 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 585 train loss_0 : -0.911 val loss_0 : -0.322 train loss_1 : 0.926 val loss_1 : 0.458 train loss_2 : 0.151 val loss_2 : 1.36 train loss_3 : 1.84 val loss_3 : 5.42 \n",
      "................................................................................................................................................................\n",
      "Epoch 590 train loss_0 : -0.91 val loss_0 : -0.349 train loss_1 : 0.925 val loss_1 : 0.473 train loss_2 : 0.149 val loss_2 : 1.25 train loss_3 : 1.79 val loss_3 : 5.46 \n",
      "................................................................................................................................................................\n",
      "Epoch 595 train loss_0 : -0.91 val loss_0 : -0.202 train loss_1 : 0.925 val loss_1 : 0.364 train loss_2 : 0.15 val loss_2 : 1.61 train loss_3 : 1.83 val loss_3 : 5.53 \n",
      "................................................................................................................................................................\n",
      "Epoch 600 train loss_0 : -0.911 val loss_0 : -0.294 train loss_1 : 0.926 val loss_1 : 0.442 train loss_2 : 0.148 val loss_2 : 1.48 train loss_3 : 1.81 val loss_3 : 5.53 \n",
      "................................................................................................................................................................\n",
      "Epoch 605 train loss_0 : -0.91 val loss_0 : -0.331 train loss_1 : 0.925 val loss_1 : 0.461 train loss_2 : 0.151 val loss_2 : 1.3 train loss_3 : 1.81 val loss_3 : 5.47 \n",
      "................................................................................................................................................................\n",
      "Epoch 610 train loss_0 : -0.911 val loss_0 : -0.26 train loss_1 : 0.926 val loss_1 : 0.412 train loss_2 : 0.147 val loss_2 : 1.52 train loss_3 : 1.81 val loss_3 : 5.47 \n",
      "................................................................................................................................................................\n",
      "Epoch 615 train loss_0 : -0.911 val loss_0 : -0.364 train loss_1 : 0.926 val loss_1 : 0.488 train loss_2 : 0.147 val loss_2 : 1.23 train loss_3 : 1.8 val loss_3 : 4.79 \n",
      "................................................................................................................................................................\n",
      "Epoch 620 train loss_0 : -0.911 val loss_0 : -0.319 train loss_1 : 0.926 val loss_1 : 0.46 train loss_2 : 0.148 val loss_2 : 1.41 train loss_3 : 1.81 val loss_3 : 5.28 \n",
      "................................................................................................................................................................\n",
      "Epoch 625 train loss_0 : -0.91 val loss_0 : -0.261 train loss_1 : 0.925 val loss_1 : 0.409 train loss_2 : 0.15 val loss_2 : 1.48 train loss_3 : 1.81 val loss_3 : 5.82 \n",
      "................................................................................................................................................................\n",
      "Epoch 630 train loss_0 : -0.912 val loss_0 : -0.349 train loss_1 : 0.927 val loss_1 : 0.483 train loss_2 : 0.148 val loss_2 : 1.33 train loss_3 : 1.8 val loss_3 : 5.39 \n",
      "................................................................................................................................................................\n",
      "Epoch 635 train loss_0 : -0.911 val loss_0 : -0.319 train loss_1 : 0.926 val loss_1 : 0.447 train loss_2 : 0.149 val loss_2 : 1.28 train loss_3 : 1.82 val loss_3 : 5.26 \n",
      "................................................................................................................................................................\n",
      "Epoch 640 train loss_0 : -0.91 val loss_0 : -0.306 train loss_1 : 0.925 val loss_1 : 0.443 train loss_2 : 0.149 val loss_2 : 1.36 train loss_3 : 1.79 val loss_3 : 5.07 \n",
      "................................................................................................................................................................\n",
      "Epoch 645 train loss_0 : -0.911 val loss_0 : -0.369 train loss_1 : 0.926 val loss_1 : 0.486 train loss_2 : 0.148 val loss_2 : 1.18 train loss_3 : 1.81 val loss_3 : 5.59 \n",
      "................................................................................................................................................................\n",
      "Epoch 650 train loss_0 : -0.912 val loss_0 : -0.384 train loss_1 : 0.927 val loss_1 : 0.508 train loss_2 : 0.145 val loss_2 : 1.23 train loss_3 : 1.78 val loss_3 : 5.15 \n",
      "................................................................................................................................................................\n",
      "Epoch 655 train loss_0 : -0.911 val loss_0 : -0.285 train loss_1 : 0.926 val loss_1 : 0.427 train loss_2 : 0.149 val loss_2 : 1.43 train loss_3 : 1.8 val loss_3 : 5.14 \n",
      "................................................................................................................................................................\n",
      "Epoch 660 train loss_0 : -0.911 val loss_0 : -0.275 train loss_1 : 0.926 val loss_1 : 0.418 train loss_2 : 0.15 val loss_2 : 1.42 train loss_3 : 1.8 val loss_3 : 5.57 \n",
      "................................................................................................................................................................\n",
      "Epoch 665 train loss_0 : -0.911 val loss_0 : -0.386 train loss_1 : 0.926 val loss_1 : 0.506 train loss_2 : 0.148 val loss_2 : 1.19 train loss_3 : 1.78 val loss_3 : 5.07 \n",
      "................................................................................................................................................................\n",
      "Epoch 670 train loss_0 : -0.911 val loss_0 : -0.217 train loss_1 : 0.926 val loss_1 : 0.373 train loss_2 : 0.151 val loss_2 : 1.55 train loss_3 : 1.83 val loss_3 : 5.73 \n",
      "................................................................................................................................................................\n",
      "Epoch 675 train loss_0 : -0.912 val loss_0 : -0.339 train loss_1 : 0.927 val loss_1 : 0.472 train loss_2 : 0.15 val loss_2 : 1.33 train loss_3 : 1.8 val loss_3 : 5.53 \n",
      "................................................................................................................................................................\n",
      "Epoch 680 train loss_0 : -0.912 val loss_0 : -0.323 train loss_1 : 0.927 val loss_1 : 0.45 train loss_2 : 0.15 val loss_2 : 1.27 train loss_3 : 1.78 val loss_3 : 5.0 \n",
      "................................................................................................................................................................\n",
      "Epoch 685 train loss_0 : -0.912 val loss_0 : -0.307 train loss_1 : 0.927 val loss_1 : 0.451 train loss_2 : 0.147 val loss_2 : 1.44 train loss_3 : 1.79 val loss_3 : 5.15 \n",
      "................................................................................................................................................................\n",
      "Epoch 690 train loss_0 : -0.91 val loss_0 : -0.358 train loss_1 : 0.925 val loss_1 : 0.494 train loss_2 : 0.15 val loss_2 : 1.36 train loss_3 : 1.79 val loss_3 : 5.22 \n",
      "................................................................................................................................................................\n",
      "Epoch 695 train loss_0 : -0.913 val loss_0 : -0.289 train loss_1 : 0.928 val loss_1 : 0.432 train loss_2 : 0.146 val loss_2 : 1.43 train loss_3 : 1.78 val loss_3 : 5.35 \n",
      "..........................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................\n",
      "Epoch 170 train loss_0 : -0.899 val loss_0 : -0.293 train loss_1 : 0.917 val loss_1 : 0.428 train loss_2 : 0.171 val loss_2 : 1.35 train loss_3 : 2.07 val loss_3 : 5.7 \n",
      "................................................................................................................................................................\n",
      "Epoch 175 train loss_0 : -0.899 val loss_0 : -0.309 train loss_1 : 0.916 val loss_1 : 0.433 train loss_2 : 0.172 val loss_2 : 1.24 train loss_3 : 2.08 val loss_3 : 5.78 \n",
      "......................."
     ]
    }
   ],
   "source": [
    "n_runs = 3\n",
    "\n",
    "for i in range(n_runs):\n",
    "    \n",
    "    model = autoencoder_cross_corr.CrossCorrAutoEncoder1D(**hp_autoencoder)\n",
    "\n",
    "    \n",
    "    loss_func = train_utils.make_complex_loss_function(mse_weight = 0.1, \n",
    "                                                       corr_weight = 1,\n",
    "                                                       manifold_weight = 0,\n",
    "                                                       bound=1)\n",
    "    train_step = train_utils.train_step\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),  # AdamW\n",
    "                       lr=config['lr'], \n",
    "                       weight_decay=config['weight_decay'])\n",
    "    \n",
    "    \n",
    "    parameters = {\n",
    "        'EPOCHS': 750,\n",
    "        'model': model, \n",
    "        'train_loader': train_loader, \n",
    "        'val_loader': val_loader, \n",
    "        'loss_function': loss_func,\n",
    "        'train_step': train_step,\n",
    "        'optimizer': optimizer, \n",
    "        'device': 'cuda', \n",
    "        'raw_test_data': test_dataset_prep,\n",
    "        'show_info': 5, \n",
    "        'num_losses': 5,\n",
    "        'labels': labels_roi,\n",
    "        'inference_function': inference.model_inference_function, \n",
    "        'to_many': config['to_many']\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    path_to_save_wandb = 'common/koval_alvi/Checkpoints/wandb_brain'\n",
    "    \n",
    "    \n",
    "    with wandb.init(project=\"eeg_fmri\", config=config, save_code=True):\n",
    "        \n",
    "        wandb.define_metric(\"val/corr_mean\", summary=\"max\")\n",
    "\n",
    "        if i == 0: \n",
    "            exp_name = wandb.run.name\n",
    "        \n",
    "        wandb.run.name = exp_name +'_run_' + str(i)\n",
    "        \n",
    "        print(config)\n",
    "        print(parameters['model'])\n",
    "        print(summary(model, torch.zeros(4, config['n_channels'],\n",
    "                                         len(config['freqs']), config['WINDOW_SIZE']), show_input=True))\n",
    "        \n",
    "        model = train_utils.wanb_train_regression(**parameters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923ea3f-b6c9-495e-bea2-36552a50cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e40a09-12c2-43b9-957f-8b37d0a0daa8",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_torch",
   "language": "python",
   "name": "myenv_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
